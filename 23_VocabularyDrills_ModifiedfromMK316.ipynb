{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VocabularyDrills_ModifiedfromMK316.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ms624atyale/Python_Basics/blob/main/23_VocabularyDrills_ModifiedfromMK316.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ¹ ğŸ¾ ğŸ© Vocabulary Drills\n",
        "\n",
        "#ğŸ“˜ **Topic 03 Pronunciation teaching**\n",
        "\n",
        "**Table of Contents:**  \n",
        "using **{gTTS}** Text-to-Speech & CMU pronunciation dictionary.  \n",
        "\n",
        "* Exposure to Keyword pronunciation (using ğŸ“Š_frequency distribution, gTTS_)\n",
        "* English rhyming (using ğŸ“ƒ_CMU dictionary_): e.g., night, right, bite, etc.\n",
        "* Learning English vowels with rhyming words.\n"
      ],
      "metadata": {
        "id": "f1lUplgVnuvM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ğŸ£ <font color = 'brown'> **Preprocessing ** â¤µï¸\n",
        "\n",
        "**For Your Information** \n",
        "\n",
        "**[NLTK package & punkt module](https://www.askpython.com/python-modules/nltk-punkt)**\n",
        "\n",
        "**[corpus-toolkit package](https://kristopherkyle.github.io/corpus_toolkit/)**\n",
        "\n",
        "  - **pip**\n",
        "    - \"pip\" is a package-management system written in Python and is used to install and manage software packages. \n",
        "    - \"pip install\" will execute the setup.py file in the current directory.\n",
        "  \n",
        "  -[package] **corpus-toolkit** is ... \n",
        "  \n",
        "  -[package] **NLTK** (Natural Language Toolkit) is used in Python to implement programs under the domain of Natural Language Processing. It contains a variety of libraries for various purposes like text classification, parsing, stemming, tokenizing, etc.\n",
        "  -[module] In NLTK, **PUNKT** is an unsupervised trainable model, which means it can be trained on unlabeled data (Data that has not been tagged with information identifying its characteristics, properties, or categories is referred to as unlabeled data.) It generates a list of sentences from a text by developing a model for words that start sentences, prepositional phrases, and abbreviations using an unsupervised technique. Without first being put to use, it has to be trained on a sizable amount of plaintext in the intended language."
      ],
      "metadata": {
        "id": "iiJrLU8I6R2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nomalization\n",
        "###**Stemming** \n",
        "* am â†’ am,   having â†’ hav,   the going â†’ the go\n",
        "\n",
        "###**Lemmatization** \n",
        "* am â†’ be,   having â†’ have,  the going â†’ the going"
      ],
      "metadata": {
        "id": "hjbq3ODJR0BC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### âœï¸ **Student's activity\n",
        "#@markdown ### ğŸ‘€. <font color = 'brown'> **Install and import packages**\n",
        "\n",
        "!pip install corpus-toolkit\n",
        "\n",
        "import nltk               #Python-internal package\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize  #from PackageName.ModuleName import FunctionName\n",
        "nltk.download('punkt')    #additional downloading of the 'punkt' module"
      ],
      "metadata": {
        "id": "wdqxWWG8A6wd",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # âœï¸ **Student's activity1** â¤µï¸\n",
        "\n",
        "!pip install corpus-toolkit\n",
        "\n",
        "import nltk               \n",
        "from nltk.tokenize import word_tokenize, sent_tokenize  \n",
        "nltk.download('punkt') "
      ],
      "metadata": {
        "id": "7klrhXnbl26S",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ’¾ Sample text: [Crime and punishment](https://raw.githubusercontent.com/ms624atyale/Data_Misc/main/Crime_Punishment_ChOne_Part.txt) Copy and get it ready to past below ğŸ‘ ğŸ‘  "
      ],
      "metadata": {
        "id": "RlifI_rHqEJM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbN8TYs6nZjK",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown #### 2.ğŸ‘€ <font color = 'brown'> **Paste your text here for analysis: (text)**\n",
        "text = input('Enter a text either by typing or doing a copy & paste:')\n",
        "\n",
        "#@markdown #### 3.ğŸ‘€ <font color = 'brown'> **Create a folder named \"txtdata\" for further processing**\n",
        "import os #os module ê°€ì ¸ì˜¤ê¸°\n",
        "os.mkdir(\"txtdata\") #os modulì˜ mkdir()function ì‚¬ìš©\n",
        "\n",
        "#@markdown #### 4.ğŸ‘€ <font color = 'brown'> **Write a text to a file under 'txtdata' folder**\n",
        "\n",
        "with open('txtdata/mytext.txt','wt') as f:\n",
        "  f.write(text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # âœï¸ **Student's activity2** â¤µï¸\n",
        "\n",
        "text = input('Enter text here:')\n",
        "\n",
        "import os \n",
        "os.mkdir(\"txtdata\") \n",
        "\n",
        "with open('txtdata/mytext.txt','wt') as f:\n",
        "  f.write(text)"
      ],
      "metadata": {
        "id": "tvJKTRRGmdnD",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ">## ğŸ£ **Frequency analysis:** your actions required two times â¤µï¸\n",
        "\n",
        "  - [Regular Expression](https://www3.ntu.edu.sg/home/ehchua/programming/howto/Regexe.html)\n",
        "\n",
        "archive: #The \" \\w \" means \"any word character\" which usually means alphanumeric (letters[a-zA-Z], numbers[0-9]) plus underscore (_). "
      ],
      "metadata": {
        "id": "TRh-brZf6ZIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown 5.ğŸ‘€ Tokenize using Regular expression & converting eveything to lower case\n",
        "\n",
        "#??getting frequency list with tagging information\n",
        "\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "retokenize = RegexpTokenizer(\"[\\w]+\") #any charcters or numbers with at least more than one character before\n",
        "words = retokenize.tokenize(text) #variable.tokenize module\n",
        "\n",
        "# Lower case\n",
        "wlist = []\n",
        "for w in words:\n",
        "  w1 = w.lower()\n",
        "  wlist.append(w1)\n",
        "\n",
        "words = wlist\n",
        "print('Word count before excluding stopwords: %d'%len(words))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "R9B_7_tyk7w8",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # âœï¸ **Student's activity3** â¤µï¸\n",
        "\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "retokenize = RegexpTokenizer(\"[\\w]+\") \n",
        "words = retokenize.tokenize(text) \n",
        "\n",
        "# Lower case\n",
        "wordlist = []\n",
        "for w in words:\n",
        "  w1 = w.lower()\n",
        "  wordlist.append(w1)\n",
        "\n",
        "words = wordlist\n",
        "print('Word count before excluding stopwords: %d'%len(words))\n",
        "\n"
      ],
      "metadata": {
        "id": "IWDcNSb1nvJo",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown 6.ğŸ‘€Remove stopwords \n",
        "\n",
        "# import stopwords from nltk.corpus\n",
        "\n",
        "from nltk.corpus import stopwords #ì—¬ê¸°ì—ì„œ stopwordsëŠ” function\n",
        "nltk.download(\"stopwords\") #module()ì•ˆì— ì‚¬ìš©í•˜ëŠ” double quotes \"\" ì†ì— function ë“¤ì–´ê°€ëŠ”ì§€ í™•ì¸ ìš”ë§\n",
        "\n",
        "words = [w for w in words if not w in stopwords.words('english')] #ì—¬ê¸°ì„œ stopwordsëŠ” moduleX, variable nameX, ë­˜ê¹Œìš”?\n",
        "print('Word count after excluding stopwords: %d'%len(words))\n",
        "\n"
      ],
      "metadata": {
        "id": "p-f1pa8QBVsY",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # âœï¸ **Student's activity4** â¤µï¸\n",
        "\n",
        "from nltk.corpus import stopwords \n",
        "nltk.download(\"stopwords\") \n",
        "\n",
        "words = [w for w in words if not w in stopwords.words('english')] \n",
        "print('Word count after excluding stopwords: %d'%len(words))\n"
      ],
      "metadata": {
        "id": "XMVip4QgoPMy",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown 7.ğŸ‘€POS Tagging (abbr. Part of Speech (i.e., grammatical categories))\n",
        "\n",
        "from corpus_toolkit import corpus_tools as ct #from ExtPackageName import ModuleName\n",
        "\n",
        "brown_corp = ct.ldcorpus(\"txtdata\") #load and read text files under 'txtdata' directory\n",
        "tok_corp = ct.tokenize(brown_corp)  #tokenize corpus - by default this lemmatizes as well\n",
        "brown_freq = ct.frequency(tok_corp) #creates a frequency dictionary\n",
        "\n",
        "ct.write_corpus(\"tagged_txt\",ct.tag(ct.ldcorpus(\"txtdata\"))) #loading & reading under the txtdata folder í•œ ê²ƒì— tagging per tokení•˜ê³ , ì´ ê²°ê³¼ë¥¼ tagged_txtë¼ëŠ” íŒŒì¼ë¡œ ì €ì¥í•˜ê¸°. \n",
        "tagged_freq = ct.frequency(ct.reload(\"tagged_txt\")) #POS tagging per tokenì„ ì €ì¥í•œ tagged_txt íŒŒì¼ì„ ë©”ëª¨ë¦¬ì— ì¬ì „ì†¡ í•˜ê³ , ì´ì— ëŒ€í•œ ë°ì´í„°ì— ë¹ˆë„ìˆ˜ ê³„ì‚°\n",
        "# ct.head(tagged_freq, hits = 10) #í† í° ë³„ POS-tagged freq ê³„ì‚°í•œ ê²°ê³¼ë¥¼ ì²˜ìŒ 10 ê°œì— ëŒ€í•˜ì—¬ ë³´ì—¬ ë‹¬ë¼. \n",
        "\n",
        "#@markdown 8.ğŸ‘€ Saving the result above as a csv file with POS information\n",
        "\n",
        "import pandas as pd #import PyIntPackage \n",
        "data_dict = tagged_freq #Assign POS-tagged freq to \"data_dict\" variable \n",
        "data_items = data_dict.items() #POS-tagged freq \"data_dic\"ë¥¼ í•­ëª©ë³„ë¡œ ì •ë¦¬\n",
        "data_list = list(data_items) #í•­ëª©ë³„ë¡œ ì •ë¦¬ëœ POS-tagged freq ë°ì´í„°ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
        "df = pd.DataFrame(data_list) #ğŸ„ë°ì´í„° ë¦¬ìŠ¤íŠ¸ê°€ ëœ ê²°ê³¼ë¥¼ íŒë‹¤ìŠ¤ í˜í‚¤ì§€ì˜ DataFrame í•¨ìˆ˜ë¥¼ ì ìš©í•´ ê·¸ ê²°ê³¼ë¥¼ \"df\" variable. \n",
        "\n",
        "df.columns=['Tagged_words','Freq'] #ğŸ„ \"df\"variable ì—´ì„ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ë¡œ í•˜ì—¬ ë‘ ìš”ì†Œë¥¼ ì“´ë‹¤. \n",
        "mycol = list(df['Tagged_words']) # \"df\" variableì— \"Tagged_words\"ë¥¼ ë¦¬ìŠ¤íŠ¸í™” í•˜ì—¬ \"mycol\" variable ë¡œ í• ë‹¹\n",
        "\n",
        "# print(df)\n",
        "\n",
        "# Word, POS into dataframe\n",
        "\n",
        "wordlist = [] #\"wordlist\" variableì— empty list ë§Œë“¤ì–´ ë†“ê³ \n",
        "cat = [] #\"cat\" variableì— empty list ë§Œë“¤ì–´ ë†“ê³ \n",
        "\n",
        "for w in mycol: #POS-tagged freqëœ tokensë¥¼ í•­ëª©í™” í•˜ê³ , ì´ë¥¼ ë¦¬ìŠ¤íŠ¸í™” í•œ ê²°ê³¼ ì¤‘ì—ì„œ 'Tagged_words'ë¥¼ ë¦¬ìŠ¤íŠ¸í™” í•œ \"mycol\" variableì—ì„œ ë‹¨ì–´ë¥¼ í•˜ë‚˜ì”© ë„ì§‘ì–´ ë‚¸ë‹¤.\n",
        "  w1 = w.split(\"_\") #ë„ì§‘ì–´ ë‚¸ ë‹¨ì–´ë¥¼ '_'ê¸°í˜¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„ë¦¬í•˜ê³  ì´ë¥¼ 'w1' variableì— í• ë‹¹\n",
        "  wordlist.append(w1[0]) #\"wordlist\" variableì— '_'ê¸°í˜¸ë¡œ ë¶„ë¦¬ëœ ë‹¨ì–´ì˜ ì²«ë²ˆì§¸ ìš”ì†Œë¥¼ ì¶”ê°€í•œë‹¤\n",
        "  cat.append(w1[1]) #ìœ„ì— ìƒì„±í•´ ë†“ì€ empty cat listì— '_'ê¸°í˜¸ë¥¼ ì‚¬ìš©í•´ ë¶„ë¦¬í•œ ë‹¨ì–´ì˜ ì²« ë²ˆì§¸ ìš”ì†Œë¥¼ ì¶”ê°€í•œë‹¤.\n",
        "\n",
        "df['Word'] = wordlist #ğŸ„???\n",
        "df['POS'] = cat #ğŸ„???\n",
        "\n",
        "#@markdown 9.ğŸ‘€ ğŸš© Sorting by? Answer [pop up box]\n",
        "\n",
        "print(\"Sorting by Frequency (type '1'), POS & Freq (type '2'), or by Word alphabetically (type '3')\")\n",
        "\n",
        "sorting = input()\n",
        "\n",
        "for t in sorting:\n",
        "  if t == \"1\":\n",
        "    df = df.sort_values(by=['Freq'], ascending = False)\n",
        "  if t == \"2\":\n",
        "    df = df.sort_values(by=['POS', 'Freq'], ascending = False)\n",
        "  if t == \"3\":\n",
        "    df = df.sort_values(by=['Word'], ascending = True)\n",
        "  else:\n",
        "    print(\"Type 1, 2, or 3\")\n",
        "df['Index'] = range(1,len(df['POS'])+1)\n",
        "\n",
        "df = df[[\"Index\", \"POS\", \"Word\",\"Freq\"]]\n",
        "# print df.to_string(index=False)\n",
        "\n",
        "#@markdown 10.ğŸ‘€ ğŸš© Saving file? Answer [pop up box]\n",
        "\n",
        "print('Save it as a file? (y/n)')\n",
        "saving = input()\n",
        "\n",
        "for s in saving:\n",
        "  if s == \"y\":\n",
        "    with open('pos_wordlist.csv','w') as f:\n",
        "      df.to_csv(f)\n",
        "    print('File is saved: pos_wordlist.csv')\n",
        "  if s == \"n\":\n",
        "    print('No file will be saved.')\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "KAeAXX8RB2kn",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # âœï¸ **Student's activity5** â¤µï¸\n",
        "\n",
        "from corpus_toolkit import corpus_tools as ct #from ExtPackageName import ModuleName\n",
        "\n",
        "brown_corp = ct.ldcorpus(\"txtdata\") #load and read text files under 'txtdata' directory\n",
        "tok_corp = ct.tokenize(brown_corp)  #tokenize corpus - by default this lemmatizes as well\n",
        "brown_freq = ct.frequency(tok_corp) #creates a frequency dictionary\n",
        "\n",
        "ct.write_corpus(\"tagged_txt\",ct.tag(ct.ldcorpus(\"txtdata\"))) #as of May 10, 2023\n",
        "\n",
        "tagged_freq = ct.frequency(ct.reload(\"tagged_txt\"))\n",
        "# ct.head(tagged_freq, hits = 10)\n",
        "\n",
        "#@markdown ğŸ”´ Result saving as a csv file with POS information\n",
        "\n",
        "import pandas as pd\n",
        "data_dict = tagged_freq\n",
        "data_items = data_dict. items()\n",
        "data_list = list(data_items)\n",
        "df = pd.DataFrame(data_list)\n",
        "\n",
        "df.columns=['Tagged_words','Freq']\n",
        "\n",
        "mycol = list(df['Tagged_words'])\n",
        "\n",
        "# print(df)\n",
        "\n",
        "# Word, POS into dataframe\n",
        "\n",
        "wlist = []\n",
        "cat = []\n",
        "\n",
        "for w in mycol:\n",
        "  w1 = w.split(\"_\")\n",
        "  wlist.append(w1[0])\n",
        "  cat.append(w1[1])\n",
        "\n",
        "df['Word'] = wlist\n",
        "df['POS'] = cat\n",
        "\n",
        "#@markdown ğŸ”µ  â–¶ï¸   Sorting by? Answer [pop up box]\n",
        "\n",
        "print(\"Sorting by Frequency (type '1'), POS & Freq (type '2'), or by Word alphabetically (type '3')\")\n",
        "sorting = input()\n",
        "\n",
        "for t in sorting:\n",
        "  if t == \"1\":\n",
        "    df = df.sort_values(by=['Freq'], ascending = False)\n",
        "  if t == \"2\":\n",
        "    df = df.sort_values(by=['POS', 'Freq'], ascending = False)\n",
        "  if t == \"3\":\n",
        "    df = df.sort_values(by=['Word'], ascending = True)\n",
        "  else:\n",
        "    print(\"Type 1, 2, or 3\")\n",
        "df['Index'] = range(1,len(df['POS'])+1)\n",
        "\n",
        "df = df[[\"Index\", \"POS\", \"Word\",\"Freq\"]]\n",
        "# print df.to_string(index=False)\n",
        "\n",
        "#@markdown ğŸ”µ  â–¶ï¸   Saving file? Answer [pop up box]\n",
        "\n",
        "print('Save it as a file? (y/n)')\n",
        "saving = input()\n",
        "\n",
        "for s in saving:\n",
        "  if s == \"y\":\n",
        "    with open('pos_wordlist.csv','w') as f:\n",
        "      df.to_csv(f)\n",
        "    print('File is saved: pos_wordlist.csv')\n",
        "  if s == \"n\":\n",
        "    print('No file will be saved.')\n",
        "\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "Bik4lR86paYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **<font color = 'red'> [TOPIC 1] Generating audio file from text (e.g., Part of Chapter 1 from Crime and Punishment by Fyodor Dostoevsky)**  \n",
        "Result file => df"
      ],
      "metadata": {
        "id": "kY-DTsXB54UN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ### âœï¸ **Student's activity 6** â¤µï¸\n",
        "#@markdown ğŸ¯ ğŸ¾**Install and import gTTS** \n",
        "%%capture\n",
        "!pip install gTTS\n",
        "from gtts import gTTS\n",
        "from IPython.display import Audio"
      ],
      "metadata": {
        "id": "JyvQPaYiACjM",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # âœï¸ **Student's activity 7** â¤µï¸\n",
        "\n",
        "#@markdown ğŸ¯ ğŸ¾**Word reading by gTTS**\n",
        "\n",
        "#@markdown ğŸš© **Select word POS:** \n",
        "\n",
        "word_POS_select = \"NOUN\" #@param = [\"NOUN\",\"VERB\",\"ADJ\",\"ADV\",\"PROPN\",\"ALL\"]\n",
        "\n",
        "wordlist = df[df['POS'] == word_POS_select]\n",
        "wordlist = wordlist.sort_values(by=['Word'], ascending = True)\n",
        "\n",
        "collist = list(wordlist['Word'])\n",
        "\n",
        "print(collist)\n",
        "\n",
        "#@markdown ğŸš© **Language to choose: (english, korean, french, spanish)**\n",
        "def tts(mytext):\n",
        "  text_to_say = mytext\n",
        "\n",
        "# Step â“µ Language to choose:\n",
        "  language_to_choose = \"en\" #@param [\"en\", \"ko\", \"fr\", 'es']\n",
        "  # lang = language_to_choose\n",
        "  language = language_to_choose\n",
        "  print(\"Play language accent: %s\"%language_to_choose)\n",
        "\n",
        "  gtts_object = gTTS(text = text_to_say,\n",
        "                     lang = language,\n",
        "                    slow = False) \n",
        "  \n",
        "  gtts_object.save(\"mytext.wav\")\n",
        "  return Audio(\"mytext.wav\")\n",
        "\n",
        "# join wordlist by adding '!': joining with '.' tend to yield an error of saying two words as one. \n",
        "text_to_say = '! '.join(collist)\n",
        "intro_text = \"Okay. I'm going to read a wordlist, so repeat after me.\"\n",
        "text_to_say = intro_text + text_to_say\n",
        "tts(text_to_say)\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "F-DZTfmtmisZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **<font color = 'red'> [TOPIC 2] Rhyming words**\n",
        "\n",
        "**_Note:_** In the following, you'll get rhyming words from CMU dictionary.  \n",
        "* [CMU pronounciation dictionary](http://www.speech.cs.cmu.edu/cgi-bin/cmudict)\n",
        "\n",
        "* [CMU tools](http://www.speech.cs.cmu.edu/tools/lextool.html)\n"
      ],
      "metadata": {
        "id": "T1Opo8LhEqqr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ˜Š Let's first set up target words for today."
      ],
      "metadata": {
        "id": "pFYEIwVxFurd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # âœï¸ **Student's activity 1** â¤µï¸\n",
        "\n",
        "#@markdown ğŸ¯ ğŸ¾**Step 1:** Install pronouncing package\n",
        "%%capture\n",
        "!pip install pronouncing\n",
        "!pip install cmudict\n",
        "\n",
        "import pronouncing\n",
        "import cmudict"
      ],
      "metadata": {
        "id": "5K7TgrhJHN5f",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\[Description]: \n",
        "\n",
        "* For a target word (your choice), we'll find rhyming words with same number of syllables. _e.g., 'grow' (1 syllable) => The result will show one-syllabled word list (randomly chosen from cmu dictionary)_\n",
        "\n",
        "* We'll then create an audio file reading the rhyming wordlist."
      ],
      "metadata": {
        "id": "eybYyZyAkRu0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # âœï¸ **Student's activity 2** â¤µï¸\n",
        "\n",
        "#@markdown ğŸ¯ ğŸ¾**Step 2:** \tğŸš© Find rhyming words with <font color = 'red'> monosyllabic word: \n",
        "\n",
        "#@markdown <font color = 'blue'> Note that I find some errors (10% of error rate in pronouncing words.)\n",
        "\n",
        "print(\"Write a monosyllabic word:\")\n",
        "rhyme_with = input()\n",
        "word = rhyme_with\n",
        "\n",
        "phones = pronouncing.phones_for_word(word)\n",
        "syll_count = pronouncing.syllable_count(phones[0])\n",
        "\n",
        "print(\"Rhyming words with %s in process.\"%word)\n",
        "\n",
        "result = pronouncing.rhymes(word)\n",
        "\n",
        "print('How many rhyming words to search? (1~20')\n",
        "n_words = input()\n",
        "n_words = int(n_words)\n",
        "\n",
        "# Among the result, select words with same syllable count\n",
        "\n",
        "wlist = []\n",
        "throw = []\n",
        "\n",
        "def syllcount(x):\n",
        "  phones = pronouncing.phones_for_word(x)\n",
        "  n = pronouncing.syllable_count(phones[0])\n",
        "  return n\n",
        "\n",
        "for w in result:\n",
        "  if syllcount(w) == syll_count:\n",
        "    wlist.append(w)\n",
        "  else:\n",
        "    throw.append(w)\n",
        "\n",
        "# random sample\n",
        "import random\n",
        "from random import shuffle\n",
        "\n",
        "b = random.sample(wlist, n_words)\n",
        "\n",
        "temp = b[:n_words]\n",
        "\n",
        "wlist = '. '.join(temp)\n",
        "intro = \"These words rhyme with \" + str(rhyme_with) + \". \" + \"Listen carefully!\"\n",
        "\n",
        "wlist = intro + wlist\n",
        "print(\"Rhyming words: %s\"%wlist)\n",
        "\n",
        "#@markdown tts() function should be defined above [1]:\n",
        "tts(wlist)\n"
      ],
      "metadata": {
        "id": "Jc46xItsjYPp",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Obg1HYCQ_wU9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **<font color = 'red'> [TOPIC 3] English vowels to learn**\n",
        "\n",
        "- /i/ vs. /I/ (high front tense-lax vowel contrast)\n",
        "- /u/ vs. /U/ (high back tense-lax vowel contrast)"
      ],
      "metadata": {
        "id": "feOryD9w0B_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # âœï¸ **Student's activity 1** â¤µï¸\n",
        "\n",
        "#@markdown ğŸ¯ ğŸ¾**Target words to learn pronunciation:**\n",
        "\n",
        "vowel_in_word = \"i_piece\" #@param [\"i_piece\", \"I_skin\", \"u_root\", \"U_good\"]\n",
        "\n",
        "ivowel = [\"piece\", \"need\",\"meet\", \"seat\",\"see\",\"bean\",\"mean\",\"lead\",\"believe\",\"meal\"]\n",
        "iv = \".  \".join(ivowel)\n",
        "uvowel = [\"root\",\"mood\",\"who\",\"rule\",\"afternoon\",\"food\",\"suit\",\"balloon\",\"cool\",\"moon\"]\n",
        "uv = \".  \".join(uvowel)\n",
        "Ivowel = [\"skin\",\"fit\",\"bit\",\"hit\",\"sit\",\"little\",\"silk\",\"milk\",\"hill\",\"ill\"]\n",
        "Iv = \".  \".join(Ivowel)\n",
        "Uvowel = [\"good\",\"book\",\"cook\",\"would\",\"could\",\"should\",\"wood\",\"wolf\",\"woman\",\"put\"]\n",
        "Uv = \".  \".join(Uvowel)\n",
        "vlist = {'i_piece': iv, 'I_skin': Iv, 'u_root': uv, 'U_good': Uv}\n",
        "\n",
        "text_to_say1 = vlist.get(vowel_in_word)\n",
        "intro = \"I'll be saying ten words that share the same vowel. Listen carefully. \"\n",
        "\n",
        "text_to_say = intro + text_to_say1\n",
        "print(vlist[vowel_in_word])\n",
        "tts(text_to_say)\n"
      ],
      "metadata": {
        "id": "6gakCNG59PiW",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # âœï¸ **Student's activity 2** â¤µï¸\n",
        "\n",
        "#@markdown ğŸ¯ ğŸ¾ **Minimal pair**\n",
        "twowords = input()\n",
        "tts(twowords)"
      ],
      "metadata": {
        "id": "lBaeuprZF-OQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **<font color = 'red'> [TOPIC 4] Larning English vowels with rhyming words**\n",
        "### **3.1 9 Monophthongs (simple vowels) and 5 diphthong vowels in English**\n",
        "\n",
        "* Note: Vowel inventories may differ from one dialect to another. We follow abstractly defined General American English vowel system. (See Ladefoged & Johnson (2017), A course in Phonetics."
      ],
      "metadata": {
        "id": "Os9nUHeEOK7g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### English monophthong vowels: 10 vowels (**The schwa vowel** is excluded here)\n",
        "\n",
        "![](https://github.com/MK316/workshop22/raw/main/img/englishvowels1.png)"
      ],
      "metadata": {
        "id": "R2PZKG9blvIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # âœï¸ **Student's activity 1** â¤µï¸\n",
        "\n",
        "#@markdown ğŸ¯ ğŸ¾**Install pronouncing, gTTS, IPython packages**\n",
        "%%capture\n",
        "!pip install pronouncing\n",
        "!pip install gTTS\n",
        "\n",
        "from gtts import gTTS\n",
        "from IPython.display import Audio\n",
        "import pronouncing"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xGu6WpNxmlIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # âœï¸ **Student's activity 2** â¤µï¸\n",
        "\n",
        "#@markdown ğŸ¯ ğŸ¾ **Step2:** ğŸš© Vowels to learn:\n",
        "\n",
        "#@markdown ğŸ³ Note: 'taught' has the same vowel with 'top' in the speaker's dialect.\n",
        "Target_vowel_as_in = \"taught\" #@param [\"bean\",\"bin\",\"Ben\",\"ban\",\"mood\",\"would\",\"taught\",\"nod\", \"mud\",\"go\",\"how\",\"bay\",\"bye\",\"boy\"]\n",
        "\n",
        "word = Target_vowel_as_in\n",
        "\n",
        "#@markdown ğŸ³ Number of syllable: 1~3 (Select \"ignore\" for not using this option.)\n",
        "number_of_syllables = \"1\" #@param [\"1\",\"2\",\"3\",\"4\",\"ignore\"]\n",
        "\n",
        "# phones = pronouncing.phones_for_word(word)\n",
        "# syll_count = pronouncing.syllable_count(phones[0])\n",
        "\n",
        "result = pronouncing.rhymes(word)\n",
        "\n",
        "# syllable number counting as function\n",
        "def syllcount(x):\n",
        "  phones = pronouncing.phones_for_word(x)\n",
        "  n = pronouncing.syllable_count(phones[0])\n",
        "  return n\n",
        "\n",
        "wlist = []\n",
        "\n",
        "# (syllcount(w) == 1 or 2)\n",
        "for w in result:\n",
        "  if (number_of_syllables == \"ignore\"):\n",
        "    wlist.append(w)\n",
        "  elif (int(number_of_syllables) == syllcount(w)) and (len(w) > 1):\n",
        "    wlist.append(w)\n",
        "  else:\n",
        "    throw.append(w)\n",
        "\n",
        "print(\"Rhyming words: %d\"%len(wlist))\n",
        "\n",
        "How_many_words_to_show = \"10\" #@param = [\"5\",\"10\",\"15\",\"20\",\"30\"]\n",
        "n_words = int(How_many_words_to_show)\n",
        "# random sample\n",
        "import random\n",
        "from random import shuffle\n",
        "\n",
        "if len(wlist) > n_words:\n",
        "  b = random.sample(wlist, n_words)\n",
        "  temp = b[:n_words]\n",
        "else:\n",
        "  temp = wlist\n",
        "\n",
        "\n",
        "# wordlist as dataframe to display\n",
        "import pandas as pd\n",
        "dft = pd.DataFrame()\n",
        "dft['Words'] = temp\n",
        "\n",
        "wlist = '. '.join(temp)\n",
        "intro = \"These are randomly chosen \" + str(n_words) + \" words that rhyme with \" + str(word) + \". \" + \"Listen carefully! \"\n",
        "\n",
        "wlist = intro + wlist\n",
        "print(\"Rhyming words: \\n %s\"%wlist)\n",
        "print(\"*** Target vowel in '%s'\"%word)\n",
        "print(dft)\n",
        "\n",
        "tts(wlist)\n"
      ],
      "metadata": {
        "id": "SemVkl3rpSnv",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # âœï¸ **Student's activity 3** â¤µï¸\n",
        "\n",
        "#@markdown ğŸ¯ ğŸ¾**More words rhyming with the word you've chosen in Student activity 2 above.\n",
        "print(result)"
      ],
      "metadata": {
        "id": "1shwPwf85e4W",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # âœï¸ **Student's activity 4** â¤µï¸\n",
        "\n",
        "#@markdown ğŸ¯ ğŸ¾** ğŸ³ Type in a word and find its stress pattern: \n",
        "wordstress = input()\n",
        "pronouncing.stresses(pronouncing.phones_for_word(wordstress)[0])"
      ],
      "metadata": {
        "id": "OmvSWUTFQSMQ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**You did a good job!** ğŸ¸ğŸ· ğŸ» ğŸ• ğŸ” ğŸŸ "
      ],
      "metadata": {
        "id": "T2bslJROG1WZ"
      }
    }
  ]
}