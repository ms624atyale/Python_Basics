{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNURo8XyfDQd5XXv2xkgqPs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "64e585d84be44966934239a6c3692e11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_74b7f82b752140cdaada48ac79b68854",
              "IPY_MODEL_44510ad646c74f838d77066bba9bb4c4"
            ],
            "layout": "IPY_MODEL_05c69a23897e411da7bf25544a8de624"
          }
        },
        "74b7f82b752140cdaada48ac79b68854": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ImageModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ImageModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ImageView",
            "format": "png",
            "height": "600",
            "layout": "IPY_MODEL_019424edc1044790b5e035540cff84f4",
            "width": "700"
          }
        },
        "44510ad646c74f838d77066bba9bb4c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1c76f5704a444a0593f1133897744edd",
              "IPY_MODEL_e7104164ccfb48b69a04488fd853131f",
              "IPY_MODEL_9859b8c4f6d84c9d801fe9622ad2e68d"
            ],
            "layout": "IPY_MODEL_aebe58e9de5a41d99e4e9fc7a343d580"
          }
        },
        "05c69a23897e411da7bf25544a8de624": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "019424edc1044790b5e035540cff84f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c76f5704a444a0593f1133897744edd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "1",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_3afb45b862624dd781a6b22f45c900ce",
            "style": "IPY_MODEL_c13015e409994f9789dc59cf661bed7c",
            "tooltip": ""
          }
        },
        "e7104164ccfb48b69a04488fd853131f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "2",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_3afb45b862624dd781a6b22f45c900ce",
            "style": "IPY_MODEL_892a748298184eac8e9a8ce85d85b485",
            "tooltip": ""
          }
        },
        "9859b8c4f6d84c9d801fe9622ad2e68d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "3",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_3afb45b862624dd781a6b22f45c900ce",
            "style": "IPY_MODEL_94135c3e612d461fbf4a9812c8c2bf59",
            "tooltip": ""
          }
        },
        "aebe58e9de5a41d99e4e9fc7a343d580": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3afb45b862624dd781a6b22f45c900ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "30px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50px"
          }
        },
        "c13015e409994f9789dc59cf661bed7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "892a748298184eac8e9a8ce85d85b485": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "94135c3e612d461fbf4a9812c8c2bf59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ms624atyale/Python_Basics/blob/main/28_Tokenization_VariousWays.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Python library & Ï†ÑÏ≤òÎ¶¨\n",
        "from IPython.display import display\n",
        "import ipywidgets as widgets\n",
        "import requests\n",
        "\n",
        "def on_button_click(button):\n",
        "    sn = int(button.description) - 1\n",
        "    image.value = requests.get(urls[sn]).content\n",
        "\n",
        "urls = [ \"https://raw.githubusercontent.com/junkyuhufs/workshop/main/slide.07.png\",\n",
        "         \"https://raw.githubusercontent.com/junkyuhufs/workshop/main/slide.08.png\",\n",
        "         \"https://raw.githubusercontent.com/junkyuhufs/workshop/main/slide.11.png\"\n",
        "]\n",
        "\n",
        "button_layout = widgets.Layout(width='50px', height='30px')\n",
        "\n",
        "buttons = [widgets.Button(description=str(i), layout=button_layout) for i in range(1, 4)]\n",
        "for button in buttons:\n",
        "    button.on_click(on_button_click)\n",
        "\n",
        "image = widgets.Image(value=requests.get(urls[0]).content, width=\"700\", height=\"600\")\n",
        "\n",
        "display(widgets.HBox([image, widgets.VBox(buttons)]))"
      ],
      "metadata": {
        "id": "Tj8kdbQDwcn3",
        "outputId": "a07e8497-5e0e-4583-f0d1-85ab3d10af55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415,
          "referenced_widgets": [
            "64e585d84be44966934239a6c3692e11",
            "74b7f82b752140cdaada48ac79b68854",
            "44510ad646c74f838d77066bba9bb4c4",
            "05c69a23897e411da7bf25544a8de624",
            "019424edc1044790b5e035540cff84f4",
            "1c76f5704a444a0593f1133897744edd",
            "e7104164ccfb48b69a04488fd853131f",
            "9859b8c4f6d84c9d801fe9622ad2e68d",
            "aebe58e9de5a41d99e4e9fc7a343d580",
            "3afb45b862624dd781a6b22f45c900ce",
            "c13015e409994f9789dc59cf661bed7c",
            "892a748298184eac8e9a8ce85d85b485",
            "94135c3e612d461fbf4a9812c8c2bf59"
          ]
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(Image(value=b'\\x89PNG\\r\\n\\x1a\\n\\x00\\x00\\x00\\rIHDR\\x00\\x00\\x03+\\x00\\x00\\x01\\xc8\\x08\\x06\\x00\\x00\\‚Ä¶"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "64e585d84be44966934239a6c3692e11"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Î¨∏Ïû• ÌÜ†ÌÅ∞Ìôî(Sentence Tokenization)\n",
        "Ïù¥Î≤àÏóêÎäî ÌÜ†ÌÅ∞Ïùò Îã®ÏúÑÍ∞Ä Î¨∏Ïû•(sentence)Ïùº Í≤ΩÏö∞Î•º ÎÖºÏùòÌï¥Î≥¥Í≤†ÏäµÎãàÎã§. Ïù¥ ÏûëÏóÖÏùÄ Í∞ñÍ≥†ÏûàÎäî ÏΩîÌçºÏä§ ÎÇ¥ÏóêÏÑú Î¨∏Ïû• Îã®ÏúÑÎ°ú Íµ¨Î∂ÑÌïòÎäî ÏûëÏóÖÏúºÎ°ú ÎïåÎ°úÎäî Î¨∏Ïû• Î∂ÑÎ•ò(sentence segmentation)ÎùºÍ≥†ÎèÑ Î∂ÄÎ¶ÖÎãàÎã§. Î≥¥ÌÜµ Í∞ñÍ≥†ÏûàÎäî ÏΩîÌçºÏä§Í∞Ä Ï†ïÏ†úÎêòÏßÄ ÏïäÏùÄ ÏÉÅÌÉúÎùºÎ©¥, ÏΩîÌçºÏä§Îäî Î¨∏Ïû• Îã®ÏúÑÎ°ú Íµ¨Î∂ÑÎêòÏñ¥ ÏûàÏßÄ ÏïäÏïÑÏÑú Ïù¥Î•º ÏÇ¨Ïö©ÌïòÍ≥†Ïûê ÌïòÎäî Ïö©ÎèÑÏóê ÎßûÍ≤å Î¨∏Ïû• ÌÜ†ÌÅ∞ÌôîÍ∞Ä ÌïÑÏöîÌï† Ïàò ÏûàÏäµÎãàÎã§.\n",
        "\n",
        "Ïñ¥ÎñªÍ≤å Ï£ºÏñ¥ÏßÑ ÏΩîÌçºÏä§Î°úÎ∂ÄÌÑ∞ Î¨∏Ïû• Îã®ÏúÑÎ°ú Î∂ÑÎ•òÌï† Ïàò ÏûàÏùÑÍπåÏöî? ÏßÅÍ¥ÄÏ†ÅÏúºÎ°ú ÏÉùÍ∞ÅÌï¥Î¥§ÏùÑ ÎïåÎäî ?ÎÇò ÎßàÏπ®Ìëú(.)ÎÇò ! Í∏∞Ï§ÄÏúºÎ°ú Î¨∏Ïû•ÏùÑ ÏûòÎùºÎÇ¥Î©¥ ÎêòÏßÄ ÏïäÏùÑÍπåÎùºÍ≥† ÏÉùÍ∞ÅÌï† Ïàò ÏûàÏßÄÎßå, Íº≠ Í∑∏Î†áÏßÄÎßåÏùÄ ÏïäÏäµÎãàÎã§. !ÎÇò ?Îäî Î¨∏Ïû•Ïùò Íµ¨Î∂ÑÏùÑ ÏúÑÌïú ÍΩ§ Î™ÖÌôïÌïú Íµ¨Î∂ÑÏûê(boundary) Ïó≠Ìï†ÏùÑ ÌïòÏßÄÎßå ÎßàÏπ®ÌëúÎäî Í∑∏Î†áÏßÄ ÏïäÍ∏∞ ÎïåÎ¨∏ÏûÖÎãàÎã§. ÎßàÏπ®ÌëúÎäî Î¨∏Ïû•Ïùò ÎÅùÏù¥ ÏïÑÎãàÎçîÎùºÎèÑ Îì±Ïû•Ìï† Ïàò ÏûàÏäµÎãàÎã§.\n",
        "\n",
        "EX1) IP 192.168.56.31 ÏÑúÎ≤ÑÏóê Îì§Ïñ¥Í∞ÄÏÑú Î°úÍ∑∏ ÌååÏùº Ï†ÄÏû•Ìï¥ÏÑú aaa@gmail.comÎ°ú Í≤∞Í≥º Ï¢Ä Î≥¥ÎÇ¥Ï§ò. Í∑∏ ÌõÑ Ï†êÏã¨ Î®πÏúºÎü¨ Í∞ÄÏûê.\n",
        "\n",
        "EX2) Since I'm actively looking for Ph.D. students, I get the same question a dozen times every year.\n",
        "\n",
        "ÏòàÎ•º Îì§Ïñ¥ ÏúÑÏùò ÏòàÏ†úÏóê ÎßàÏπ®ÌëúÎ•º Í∏∞Ï§ÄÏúºÎ°ú Î¨∏Ïû• ÌÜ†ÌÅ∞ÌôîÎ•º Ï†ÅÏö©Ìï¥Î≥∏Îã§Î©¥ Ïñ¥Îñ®ÍπåÏöî? Ï≤´Î≤àÏß∏ ÏòàÏ†úÏóêÏÑúÎäî Î≥¥ÎÇ¥Ï§ò.ÏóêÏÑú Í∑∏Î¶¨Í≥† ÎëêÎ≤àÏß∏ ÏòàÏ†úÏóêÏÑúÎäî year.ÏóêÏÑú Ï≤òÏùåÏúºÎ°ú Î¨∏Ïû•Ïù¥ ÎÅùÎÇú Í≤ÉÏúºÎ°ú Ïù∏ÏãùÌïòÎäî Í≤ÉÏù¥ Ï†úÎåÄÎ°ú Î¨∏Ïû•Ïùò ÎÅùÏùÑ ÏòàÏ∏°ÌñàÎã§Í≥† Î≥º Ïàò ÏûàÏäµÎãàÎã§. ÌïòÏßÄÎßå Îã®ÏàúÌûà ÎßàÏπ®Ìëú(.)Î°ú Î¨∏Ïû•ÏùÑ Íµ¨Î∂ÑÏßìÎäîÎã§Í≥† Í∞ÄÏ†ïÌïòÎ©¥, Î¨∏Ïû•Ïùò ÎÅùÏù¥ ÎÇòÏò§Í∏∞ Ï†ÑÏóê Ïù¥ÎØ∏ ÎßàÏπ®ÌëúÍ∞Ä Ïó¨Îü¨Î≤à Îì±Ïû•ÌïòÏó¨ ÏòàÏÉÅÌïú Í≤∞Í≥ºÍ∞Ä ÎÇòÏò§ÏßÄ ÏïäÍ≤å Îê©ÎãàÎã§.\n",
        "\n",
        "ÏÇ¨Ïö©ÌïòÎäî ÏΩîÌçºÏä§Í∞Ä Ïñ¥Îñ§ Íµ≠Ï†ÅÏùò Ïñ∏Ïñ¥Ïù∏ÏßÄ, ÎòêÎäî Ìï¥Îãπ ÏΩîÌçºÏä§ ÎÇ¥ÏóêÏÑú ÌäπÏàòÎ¨∏ÏûêÎì§Ïù¥ Ïñ¥ÎñªÍ≤å ÏÇ¨Ïö©ÎêòÍ≥† ÏûàÎäîÏßÄÏóê Îî∞ÎùºÏÑú ÏßÅÏ†ë Í∑úÏπôÎì§ÏùÑ Ï†ïÏùòÌï¥Î≥º Ïàò ÏûàÍ≤†ÏäµÎãàÎã§. 100% Ï†ïÌôïÎèÑÎ•º ÏñªÎäî ÏùºÏùÄ Ïâ¨Ïö¥ ÏùºÏù¥ ÏïÑÎãåÎç∞, Í∞ñÍ≥†ÏûàÎäî ÏΩîÌçºÏä§ Îç∞Ïù¥ÌÑ∞Ïóê Ïò§ÌÉÄÎÇò, Î¨∏Ïû•Ïùò Íµ¨ÏÑ±Ïù¥ ÏóâÎßùÏù¥ÎùºÎ©¥ Ï†ïÌï¥ÎÜìÏùÄ Í∑úÏπôÏù¥ ÏÜåÏö©Ïù¥ ÏóÜÏùÑ Ïàò ÏûàÍ∏∞ ÎïåÎ¨∏ÏûÖÎãàÎã§.\n",
        "\n",
        "NLTKÏóêÏÑúÎäî ÏòÅÏñ¥ Î¨∏Ïû•Ïùò ÌÜ†ÌÅ∞ÌôîÎ•º ÏàòÌñâÌïòÎäî sent_tokenizeÎ•º ÏßÄÏõêÌïòÍ≥† ÏûàÏäµÎãàÎã§. NLTKÎ•º ÌÜµÌï¥ Î¨∏Ïû• ÌÜ†ÌÅ∞ÌôîÎ•º Ïã§ÏäµÌï¥Î≥¥Í≤†ÏäµÎãàÎã§."
      ],
      "metadata": {
        "id": "PHOoPaU2OkGw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "qWcgp3AzSyi4",
        "outputId": "98239586-b732-4791-e8b7-c155328afcab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.65.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üêπ sent_tokenize()\n",
        "\n",
        "* I am not happy with results with conjunctions, post-numbers, etc. "
      ],
      "metadata": {
        "id": "eZ37_yhXOmFC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "sentences = \"I'm actively looking for Ph.D. students. \\\n",
        "and you are a Ph.D student. \\\n",
        "Visit IP 192.168.56.31 \\\n",
        "and send the results to my email account. \\\n",
        "It's email@gmail.com.\"\n",
        "\n",
        "sentence = sent_tokenize(sentences)\n",
        "print('Î¨∏Ïû• ÌÜ†ÌÅ∞Ìôî: %s' %sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kv8s_PN-OlG_",
        "outputId": "0f15a4ce-7fbc-4fd4-dd4c-02ae12250c45"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Î¨∏Ïû• ÌÜ†ÌÅ∞Ìôî: [\"I'm actively looking for Ph.D. students.\", 'and you are a Ph.D student.', 'Visit IP 192.168.56.31 and send the results to my email account.', \"It's email@gmail.com.\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üçî üçü üç©  <font color = 'blue'> **Under construction**\n",
        "\n",
        "### <font color = 'red'> **Corpus data (e.g., crawling) should be preprocessed before further analysis by means of Cleaning(Ï†ïÏ†ú), Normalization(Ï†ïÍ∑úÌôî), & Tokenization(ÌÜ†ÌÅ∞Ìôî)**. \n",
        "* [English Tokenization](https://wikidocs.net/21698)\n",
        "\n",
        "## Cleaning\n",
        "* Íµ¨ÎëêÏ†ê(punctuation (e.g., \".\", \",\", \"?\", \"!\", \";\", \":\")ÏùÑ ÏßÄÏö∞Í∏∞\n",
        "* ÌäπÏàòÎ¨∏Ïûê Î™®Îëê ÏßÄÏö∞Í∏∞\n",
        "\n",
        "<font color = 'green'> Simplest tokenization: Íµ¨ÎëêÏ†ê ÏßÄÏö¥ ÌõÑ ÎùÑÏñ¥Ïì∞Í∏∞(whitespace)Î•º Í∏∞Ï§ÄÏúºÎ°ú ÏûòÎùºÎÇ¥Í∏∞ Ï†úÏô∏\n",
        "\n",
        "\n",
        "## Normalization\n",
        "\n",
        "* Stemming: am ‚Üí am, the going ‚Üí the go, having ‚Üí hav\n",
        "* Lemmatization: am ‚Üí be, the going ‚Üí the going, having ‚Üí have\n",
        "\n",
        "\n",
        "## Tokenization \n",
        "\n",
        "* Tokenization: Ï£ºÏñ¥ÏßÑ ÏΩîÌçºÏä§(corpus)ÏóêÏÑú ÌÜ†ÌÅ∞(token)Ïù¥Îùº Î∂àÎ¶¨Îäî Îã®ÏúÑ (e.g., word, phrase, strings with meaning)Î°ú ÎÇòÎàÑÎäî ÏûëÏóÖ\n",
        "* ÌÜ†ÌÅ∞Ïùò Îã®ÏúÑÍ∞Ä ÏÉÅÌô©Ïóê Îî∞Îùº Îã§Î•¥ÏßÄÎßå, Î≥¥ÌÜµ ÏùòÎØ∏ÏûàÎäî Îã®ÏúÑÎ°ú ÌÜ†ÌÅ∞ÏùÑ Ï†ïÏùòÌï©ÎãàÎã§. \n",
        "* NLTK, KoNLPYÎ•º ÌÜµÌï¥ Ïã§ÏäµÏùÑ ÏßÑÌñâÌïòÎ©∞ ÌÜ†ÌÅ∞Ìôî\n",
        "\n"
      ],
      "metadata": {
        "id": "gb1sh28mTSox"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üÜò What is PunktSentenceTokenizer?\n",
        "For more information read the original article\n",
        "In NLTK, PUNKT is an unsupervised trainable model, which means it can be trained on unlabeled data (Data that has not been tagged with information identifying its characteristics, properties, or categories is referred to as unlabeled data.)\n",
        "\n",
        "It generates a list of sentences from a text by developing a model for words that start sentences, prepositional phrases, and abbreviations using an unsupervised technique. Without first being put to use, it has to be trained on a sizable amount of plaintext in the intended language."
      ],
      "metadata": {
        "id": "ERqTcAMoywIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'Here‚Äôs to the crazy ones, the misfits, the rebels, the troublemakers, the round pegs in the square holes. \\\n",
        "The ones who see things differently ‚Äî they‚Äôre not fond of rules. \\\n",
        "I wanted to pay with a twenty-dolloar bill; however, she couldn‚Äôt get cash. \\\n",
        "I like Brown‚Äôs East back pack,\\\n",
        "I‚Äôve got a big trouble, but other people were having lots of fun. \\\n",
        "I like Brown‚Äôs East back pack,\\\n",
        "but she doesn‚Äôt.'"
      ],
      "metadata": {
        "id": "4odDoSnPS18k"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QovcT0MjS7gp",
        "outputId": "7ac86d74-b2a0-4ed0-fa92-ccd7c7facaf2"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here‚Äôs to the crazy ones, the misfits, the rebels, the troublemakers, the round pegs in the square holes. The ones who see things differently ‚Äî they‚Äôre not fond of rules. I wanted to pay with a twenty-dolloar bill; however, she couldn‚Äôt get cash. I like Brown‚Äôs East back pack,I‚Äôve got a big trouble, but other people were having lots of fun. I like Brown‚Äôs East back pack,but she doesn‚Äôt.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = open('/content/sample_data/exercise/text_symbol_sample.txt','rt')\n",
        "file.read()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "gbFvGofSTFDR",
        "outputId": "975841bc-d28e-4dc2-f2f6-a29a7f582900"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Here‚Äôs to the crazy ones, the misfits, the rebels, the troublemakers, the round pegs in the square holes.\\nThe ones who see things differently ‚Äî they‚Äôre not fond of rules. \\nI wanted to pay with a twenty-dolloar bill; \\nhowever, but she couldn‚Äôt get cash. \\nI‚Äôve got a big trouble, but other people were having lots of fun. \\nI like Brown‚Äôs East back pack,\\nbut she doesn‚Äôt.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = open('/content/sample_data/exercise/text_symbol_sample.txt','rt')\n",
        "file.read().replace(\"\\n\", \" \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "afJEPVK-0zZl",
        "outputId": "6993f722-6a24-4cc6-a567-509d28413486"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Here‚Äôs to the crazy ones, the misfits, the rebels, the troublemakers, the round pegs in the square holes. The ones who see things differently ‚Äî they‚Äôre not fond of rules.  I wanted to pay with a twenty-dolloar bill;  however, but she couldn‚Äôt get cash.  I‚Äôve got a big trouble, but other people were having lots of fun.  I like Brown‚Äôs East back pack, but she doesn‚Äôt.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simplest way to tokenize a text into units."
      ],
      "metadata": {
        "id": "sTnGhW7YrT_3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file = open('/content/sample_data/exercise/text_symbol_sample.txt','rt')\n",
        "obj = file.read().replace(\"\\n\", \" \")\n",
        "obj.split()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWBNRkayhJeF",
        "outputId": "08025c29-44b7-4bed-8229-22fd7391eea1"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Here‚Äôs',\n",
              " 'to',\n",
              " 'the',\n",
              " 'crazy',\n",
              " 'ones,',\n",
              " 'the',\n",
              " 'misfits,',\n",
              " 'the',\n",
              " 'rebels,',\n",
              " 'the',\n",
              " 'troublemakers,',\n",
              " 'the',\n",
              " 'round',\n",
              " 'pegs',\n",
              " 'in',\n",
              " 'the',\n",
              " 'square',\n",
              " 'holes.',\n",
              " 'The',\n",
              " 'ones',\n",
              " 'who',\n",
              " 'see',\n",
              " 'things',\n",
              " 'differently',\n",
              " '‚Äî',\n",
              " 'they‚Äôre',\n",
              " 'not',\n",
              " 'fond',\n",
              " 'of',\n",
              " 'rules.',\n",
              " 'I',\n",
              " 'wanted',\n",
              " 'to',\n",
              " 'pay',\n",
              " 'with',\n",
              " 'a',\n",
              " 'twenty-dolloar',\n",
              " 'bill;',\n",
              " 'however,',\n",
              " 'but',\n",
              " 'she',\n",
              " 'couldn‚Äôt',\n",
              " 'get',\n",
              " 'cash.',\n",
              " 'I‚Äôve',\n",
              " 'got',\n",
              " 'a',\n",
              " 'big',\n",
              " 'trouble,',\n",
              " 'but',\n",
              " 'other',\n",
              " 'people',\n",
              " 'were',\n",
              " 'having',\n",
              " 'lots',\n",
              " 'of',\n",
              " 'fun.',\n",
              " 'I',\n",
              " 'like',\n",
              " 'Brown‚Äôs',\n",
              " 'East',\n",
              " 'back',\n",
              " 'pack,',\n",
              " 'but',\n",
              " 'she',\n",
              " 'doesn‚Äôt.']"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üêπ nltk.tokenize.**word_tokenize()**\n",
        "\n",
        "* <font color = 'sky blue'> Punctuations as well as symbols such as a phrase-linking hiphen\"-\" and an apostrophe \"'\"(perfect tense, possessive) are tokenized.\n",
        "* <font color = 'sky blue'> cf., A within-word hiphen belongs to a word (e.g., 'ten-dollar'), not being tokenized on its own ."
      ],
      "metadata": {
        "id": "A03RIU6gnLZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "import nltk \n",
        "nltk.download('punkt')\n",
        "\n",
        "print('Tokenizing Word and Punctuation:',word_tokenize(obj)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9Pfw0_Thhka",
        "outputId": "d1804b28-a257-452a-c39a-e8437a749c95"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing Word and Punctuation: ['Here', '‚Äô', 's', 'to', 'the', 'crazy', 'ones', ',', 'the', 'misfits', ',', 'the', 'rebels', ',', 'the', 'troublemakers', ',', 'the', 'round', 'pegs', 'in', 'the', 'square', 'holes', '.', 'The', 'ones', 'who', 'see', 'things', 'differently', '‚Äî', 'they', '‚Äô', 're', 'not', 'fond', 'of', 'rules', '.', 'I', 'wanted', 'to', 'pay', 'with', 'a', 'twenty-dolloar', 'bill', ';', 'however', ',', 'but', 'she', 'couldn', '‚Äô', 't', 'get', 'cash', '.', 'I', '‚Äô', 've', 'got', 'a', 'big', 'trouble', ',', 'but', 'other', 'people', 'were', 'having', 'lots', 'of', 'fun', '.', 'I', 'like', 'Brown', '‚Äô', 's', 'East', 'back', 'pack', ',', 'but', 'she', 'doesn', '‚Äô', 't', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Advanced for a print codeline.\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk \n",
        "nltk.download('punkt')\n",
        "result1 = word_tokenize(obj)\n",
        "\n",
        "print('Tokenizing Word and Punctuation: %s' %result1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1NIz986mFTA",
        "outputId": "91fc961a-6aef-46ef-edb7-c850a1c590ab"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing Word and Punctuation: ['Here', '‚Äô', 's', 'to', 'the', 'crazy', 'ones', ',', 'the', 'misfits', ',', 'the', 'rebels', ',', 'the', 'troublemakers', ',', 'the', 'round', 'pegs', 'in', 'the', 'square', 'holes', '.', 'The', 'ones', 'who', 'see', 'things', 'differently', '‚Äî', 'they', '‚Äô', 're', 'not', 'fond', 'of', 'rules', '.', 'I', 'wanted', 'to', 'pay', 'with', 'a', 'twenty-dolloar', 'bill', ';', 'however', ',', 'but', 'she', 'couldn', '‚Äô', 't', 'get', 'cash', '.', 'I', '‚Äô', 've', 'got', 'a', 'big', 'trouble', ',', 'but', 'other', 'people', 'were', 'having', 'lots', 'of', 'fun', '.', 'I', 'like', 'Brown', '‚Äô', 's', 'East', 'back', 'pack', ',', 'but', 'she', 'doesn', '‚Äô', 't', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üêπ nltk.tokenize.**WordPunctTokenizer()**\n",
        "\n",
        "* <font color = 'sky blue'> Punctuations (\".\", \",\", \".\", \";\"), a phrase-linking hypthen (\"-\"), a word-linking hyphen (\"-\"), and an apostrophe (\"'\") (perfect tense, possessive, negation)) are tokenized as a unit across the board.\n",
        "\n",
        "  * <font color = 'pink'> Wrong command: >>WordPunctTokenizer(txt) or WordPunctTokenizer.tokenize(txt): Error message: WordPunctTokenizer.__init__() takes 1 positional argument but 2 were given."
      ],
      "metadata": {
        "id": "lOu9-q_Cn01a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "\n",
        "print('Tokenizing Words and Punctuations:', WordPunctTokenizer().tokenize(obj)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYAWzvgbhiwd",
        "outputId": "216a7097-ca50-4593-a6fa-1ba9ddd953ff"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing Words and Punctuations: ['Here', '‚Äô', 's', 'to', 'the', 'crazy', 'ones', ',', 'the', 'misfits', ',', 'the', 'rebels', ',', 'the', 'troublemakers', ',', 'the', 'round', 'pegs', 'in', 'the', 'square', 'holes', '.', 'The', 'ones', 'who', 'see', 'things', 'differently', '‚Äî', 'they', '‚Äô', 're', 'not', 'fond', 'of', 'rules', '.', 'I', 'wanted', 'to', 'pay', 'with', 'a', 'twenty', '-', 'dolloar', 'bill', ';', 'however', ',', 'but', 'she', 'couldn', '‚Äô', 't', 'get', 'cash', '.', 'I', '‚Äô', 've', 'got', 'a', 'big', 'trouble', ',', 'but', 'other', 'people', 'were', 'having', 'lots', 'of', 'fun', '.', 'I', 'like', 'Brown', '‚Äô', 's', 'East', 'back', 'pack', ',', 'but', 'she', 'doesn', '‚Äô', 't', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "result2 = WordPunctTokenizer().tokenize(obj)\n",
        "\n",
        "print('Tokenizing Words and Punctuations: %s' %result2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kfxxv5cImhFa",
        "outputId": "d7f5a1c2-57be-4af5-8499-dcc1200422f4"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing Words and Punctuations: ['Here', '‚Äô', 's', 'to', 'the', 'crazy', 'ones', ',', 'the', 'misfits', ',', 'the', 'rebels', ',', 'the', 'troublemakers', ',', 'the', 'round', 'pegs', 'in', 'the', 'square', 'holes', '.', 'The', 'ones', 'who', 'see', 'things', 'differently', '‚Äî', 'they', '‚Äô', 're', 'not', 'fond', 'of', 'rules', '.', 'I', 'wanted', 'to', 'pay', 'with', 'a', 'twenty', '-', 'dolloar', 'bill', ';', 'however', ',', 'but', 'she', 'couldn', '‚Äô', 't', 'get', 'cash', '.', 'I', '‚Äô', 've', 'got', 'a', 'big', 'trouble', ',', 'but', 'other', 'people', 'were', 'having', 'lots', 'of', 'fun', '.', 'I', 'like', 'Brown', '‚Äô', 's', 'East', 'back', 'pack', ',', 'but', 'she', 'doesn', '‚Äô', 't', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üêπ tensorflow.keras.preprocessing.text.**text_to_word_sequence()**\n",
        "\n",
        "* <font color = 'sky blue'> Small letters across the board\n",
        "* An apostrophe (\"'\" for Perfect tense (e.g., \"I've\"), possessive (e.g., \"John's\"), negation (e.g., 'doesn't)) is part of a token.\n",
        "* A phrase-linking hyphen (-) are tokenized. \n",
        "* **All punctuations and a word-linking phyphen are deleted**. \n"
      ],
      "metadata": {
        "id": "boMBjWuFptSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "\n",
        "print('Tokenizing Words after Cleaning Punctuations:', text_to_word_sequence(obj))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aowUE2sTrAi6",
        "outputId": "88e899b2-4434-4995-d03c-2e2233ad2e14"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing Words after Cleaning Punctuations: ['here‚Äôs', 'to', 'the', 'crazy', 'ones', 'the', 'misfits', 'the', 'rebels', 'the', 'troublemakers', 'the', 'round', 'pegs', 'in', 'the', 'square', 'holes', 'the', 'ones', 'who', 'see', 'things', 'differently', '‚Äî', 'they‚Äôre', 'not', 'fond', 'of', 'rules', 'i', 'wanted', 'to', 'pay', 'with', 'a', 'twenty', 'dolloar', 'bill', 'however', 'but', 'she', 'couldn‚Äôt', 'get', 'cash', 'i‚Äôve', 'got', 'a', 'big', 'trouble', 'but', 'other', 'people', 'were', 'having', 'lots', 'of', 'fun', 'i', 'like', 'brown‚Äôs', 'east', 'back', 'pack', 'but', 'she', 'doesn‚Äôt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
        "result3 = text_to_word_sequence(obj)\n",
        "\n",
        "print('Tokenizing Words after Cleaning Punctuations: %s' %result3)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KvxuBHrhler",
        "outputId": "dcbbbcd4-4b1f-4cac-a664-bbad7cec1cde"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing Words after Cleaning Punctuations: ['here‚Äôs', 'to', 'the', 'crazy', 'ones', 'the', 'misfits', 'the', 'rebels', 'the', 'troublemakers', 'the', 'round', 'pegs', 'in', 'the', 'square', 'holes', 'the', 'ones', 'who', 'see', 'things', 'differently', '‚Äî', 'they‚Äôre', 'not', 'fond', 'of', 'rules', 'i', 'wanted', 'to', 'pay', 'with', 'a', 'twenty', 'dolloar', 'bill', 'however', 'but', 'she', 'couldn‚Äôt', 'get', 'cash', 'i‚Äôve', 'got', 'a', 'big', 'trouble', 'but', 'other', 'people', 'were', 'having', 'lots', 'of', 'fun', 'i', 'like', 'brown‚Äôs', 'east', 'back', 'pack', 'but', 'she', 'doesn‚Äôt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ** RegexpTokenizer + PorterStemmer ÏóêÏÑúÎäî punctuation, other symbols are deleted (Check later as of May 21, 2023)"
      ],
      "metadata": {
        "id": "58snfSOY42Qq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "retokenize = RegexpTokenizer(\"[\\w]+\")\n",
        "result4 = retokenize.tokenize(obj)\n",
        "\n",
        "print('Tokenizing Words with RegexpTokenizer: %s' %result4)"
      ],
      "metadata": {
        "id": "zcfE8gZd4S9j",
        "outputId": "def99b25-7dd8-42fa-cfc1-e12add471c26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing Words with RegexpTokenizer: ['Here', 's', 'to', 'the', 'crazy', 'ones', 'the', 'misfits', 'the', 'rebels', 'the', 'troublemakers', 'the', 'round', 'pegs', 'in', 'the', 'square', 'holes', 'The', 'ones', 'who', 'see', 'things', 'differently', 'they', 're', 'not', 'fond', 'of', 'rules', 'I', 'wanted', 'to', 'pay', 'with', 'a', 'twenty', 'dolloar', 'bill', 'however', 'but', 'she', 'couldn', 't', 'get', 'cash', 'I', 've', 'got', 'a', 'big', 'trouble', 'but', 'other', 'people', 'were', 'having', 'lots', 'of', 'fun', 'I', 'like', 'Brown', 's', 'East', 'back', 'pack', 'but', 'she', 'doesn', 't']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stemming"
      ],
      "metadata": {
        "id": "9O-CbxvV-DG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import LancasterStemmer\n",
        "stemmer = LancasterStemmer()\n",
        "[stemmer.stem(w) for w in result4]"
      ],
      "metadata": {
        "id": "VDmNAzQJ69b5",
        "outputId": "eb1133c4-d787-4f5a-8cf4-0660e0bcb010",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['her',\n",
              " 's',\n",
              " 'to',\n",
              " 'the',\n",
              " 'crazy',\n",
              " 'on',\n",
              " 'the',\n",
              " 'misfit',\n",
              " 'the',\n",
              " 'rebel',\n",
              " 'the',\n",
              " 'troublemak',\n",
              " 'the',\n",
              " 'round',\n",
              " 'peg',\n",
              " 'in',\n",
              " 'the',\n",
              " 'squ',\n",
              " 'hol',\n",
              " 'the',\n",
              " 'on',\n",
              " 'who',\n",
              " 'see',\n",
              " 'thing',\n",
              " 'diff',\n",
              " 'they',\n",
              " 're',\n",
              " 'not',\n",
              " 'fond',\n",
              " 'of',\n",
              " 'rul',\n",
              " 'i',\n",
              " 'want',\n",
              " 'to',\n",
              " 'pay',\n",
              " 'with',\n",
              " 'a',\n",
              " 'twenty',\n",
              " 'dollo',\n",
              " 'bil',\n",
              " 'howev',\n",
              " 'but',\n",
              " 'she',\n",
              " 'couldn',\n",
              " 't',\n",
              " 'get',\n",
              " 'cash',\n",
              " 'i',\n",
              " 've',\n",
              " 'got',\n",
              " 'a',\n",
              " 'big',\n",
              " 'troubl',\n",
              " 'but',\n",
              " 'oth',\n",
              " 'peopl',\n",
              " 'wer',\n",
              " 'hav',\n",
              " 'lot',\n",
              " 'of',\n",
              " 'fun',\n",
              " 'i',\n",
              " 'lik',\n",
              " 'brown',\n",
              " 's',\n",
              " 'east',\n",
              " 'back',\n",
              " 'pack',\n",
              " 'but',\n",
              " 'she',\n",
              " 'doesn',\n",
              " 't']"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lematization \n",
        "\n",
        "* PB: no be copular verb retrieved... why?"
      ],
      "metadata": {
        "id": "oKUV4LRB-H4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "[stemmer.stem(w) for w in result4] # words Î°ú list comprehension. Ïù¥ ÏõåÏ¶àÏóêÏÑú ÌïòÎÇòÌïòÎÇòÏî© Î£®ÌîÑÎ•º ÎèÑÎäîÎç∞, Îã®Ïñ¥Î•º w Ïóê Îã¥ÏïÑÏÑú, ÏïûÏóê stemmer.stem () Ìï®ÏàòÍ∞Ä Ïã§ÌñâÎêúÎã§. Ïñ¥Îñ§ Ìï®ÏàòÎäî Ïñ¥Îñ§ Ïû•/Îã®Ï†êÏù¥ ÏûàÍµ¨ÎÇò.\n",
        "#small letter change  "
      ],
      "metadata": {
        "id": "BjKZYeOH5kMi",
        "outputId": "cc7a85e8-a7af-4e81-ef6d-851bb3138bd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['here',\n",
              " 's',\n",
              " 'to',\n",
              " 'the',\n",
              " 'crazi',\n",
              " 'one',\n",
              " 'the',\n",
              " 'misfit',\n",
              " 'the',\n",
              " 'rebel',\n",
              " 'the',\n",
              " 'troublemak',\n",
              " 'the',\n",
              " 'round',\n",
              " 'peg',\n",
              " 'in',\n",
              " 'the',\n",
              " 'squar',\n",
              " 'hole',\n",
              " 'the',\n",
              " 'one',\n",
              " 'who',\n",
              " 'see',\n",
              " 'thing',\n",
              " 'differ',\n",
              " 'they',\n",
              " 're',\n",
              " 'not',\n",
              " 'fond',\n",
              " 'of',\n",
              " 'rule',\n",
              " 'i',\n",
              " 'want',\n",
              " 'to',\n",
              " 'pay',\n",
              " 'with',\n",
              " 'a',\n",
              " 'twenti',\n",
              " 'dolloar',\n",
              " 'bill',\n",
              " 'howev',\n",
              " 'but',\n",
              " 'she',\n",
              " 'couldn',\n",
              " 't',\n",
              " 'get',\n",
              " 'cash',\n",
              " 'i',\n",
              " 've',\n",
              " 'got',\n",
              " 'a',\n",
              " 'big',\n",
              " 'troubl',\n",
              " 'but',\n",
              " 'other',\n",
              " 'peopl',\n",
              " 'were',\n",
              " 'have',\n",
              " 'lot',\n",
              " 'of',\n",
              " 'fun',\n",
              " 'i',\n",
              " 'like',\n",
              " 'brown',\n",
              " 's',\n",
              " 'east',\n",
              " 'back',\n",
              " 'pack',\n",
              " 'but',\n",
              " 'she',\n",
              " 'doesn',\n",
              " 't']"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AGAIN as of May 21, 2023"
      ],
      "metadata": {
        "id": "HuRtnY3n-9fb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer # ÌôúÏö©ÏùÑ Î≥µÏõêÌïòÏó¨ Îã®Ïñ¥Î•º Ï∂îÏ∂úÌï¥Ï§å. \n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "[lemmatizer.lemmatize(w) for w in result4]"
      ],
      "metadata": {
        "id": "rsZNA64a-xIB",
        "outputId": "c2d2bafb-7ad8-4f9c-990d-b147515b6225",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Here',\n",
              " 's',\n",
              " 'to',\n",
              " 'the',\n",
              " 'crazy',\n",
              " 'one',\n",
              " 'the',\n",
              " 'misfit',\n",
              " 'the',\n",
              " 'rebel',\n",
              " 'the',\n",
              " 'troublemaker',\n",
              " 'the',\n",
              " 'round',\n",
              " 'peg',\n",
              " 'in',\n",
              " 'the',\n",
              " 'square',\n",
              " 'hole',\n",
              " 'The',\n",
              " 'one',\n",
              " 'who',\n",
              " 'see',\n",
              " 'thing',\n",
              " 'differently',\n",
              " 'they',\n",
              " 're',\n",
              " 'not',\n",
              " 'fond',\n",
              " 'of',\n",
              " 'rule',\n",
              " 'I',\n",
              " 'wanted',\n",
              " 'to',\n",
              " 'pay',\n",
              " 'with',\n",
              " 'a',\n",
              " 'twenty',\n",
              " 'dolloar',\n",
              " 'bill',\n",
              " 'however',\n",
              " 'but',\n",
              " 'she',\n",
              " 'couldn',\n",
              " 't',\n",
              " 'get',\n",
              " 'cash',\n",
              " 'I',\n",
              " 've',\n",
              " 'got',\n",
              " 'a',\n",
              " 'big',\n",
              " 'trouble',\n",
              " 'but',\n",
              " 'other',\n",
              " 'people',\n",
              " 'were',\n",
              " 'having',\n",
              " 'lot',\n",
              " 'of',\n",
              " 'fun',\n",
              " 'I',\n",
              " 'like',\n",
              " 'Brown',\n",
              " 's',\n",
              " 'East',\n",
              " 'back',\n",
              " 'pack',\n",
              " 'but',\n",
              " 'she',\n",
              " 'doesn',\n",
              " 't']"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stopwords Î∂àÏö©Ïñ¥\n",
        "For more information, read the original article\n",
        "\n",
        "Stopwords are the English words which does not add much meaning to a sentence. They can safely be ignored without sacrificing the meaning of the sentence. For example, the words like the, he, have etc. Such words are already captured this in corpus named corpus. We first download it to our python environment.\n",
        "\n",
        "Stop words are common words like ‚Äòthe‚Äô, ‚Äòand‚Äô, ‚ÄòI‚Äô, etc. that are very frequent in text, and so don‚Äôt convey insights into the specific topic of a document. We can remove these stop words from the text in a given corpus to clean up the data, and identify words that are more rare and potentially more relevant to what we‚Äôre interested in.\n",
        "\n",
        "Text may contain stop words like ‚Äòthe‚Äô, ‚Äòis‚Äô, ‚Äòare‚Äô. Stop words can be filtered from the text to be processed. There is no universal list of stop words in nlp research, however the nltk module contains a list of stop words."
      ],
      "metadata": {
        "id": "Paej0i2D_PRg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "advlsIDW_K0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion: \n",
        "\n",
        "ÌÜ†ÌÅ∞Ìôî ÏûëÏóÖÏùÑ Îã®ÏàúÌïòÍ≤å ÏΩîÌçºÏä§ÏóêÏÑú Íµ¨ÎëêÏ†êÏùÑ Ï†úÏô∏ÌïòÍ≥† Í≥µÎ∞± Í∏∞Ï§ÄÏúºÎ°ú ÏûòÎùºÎÇ¥Îäî ÏûëÏóÖÏù¥ÎùºÍ≥† Í∞ÑÏ£ºÌï† ÏàòÎäî ÏóÜÏäµÎãàÎã§. \n",
        "\n",
        "1) Íµ¨ÎëêÏ†êÏù¥ÎÇò ÌäπÏàò Î¨∏ÏûêÎ•º Îã®Ïàú Ï†úÏô∏Ìï¥ÏÑúÎäî Ïïà ÎêúÎã§.\n",
        "Í∞ñÍ≥†ÏûàÎäî ÏΩîÌçºÏä§ÏóêÏÑú Îã®Ïñ¥Îì§ÏùÑ Í±∏Îü¨ÎÇº Îïå, Íµ¨ÎëêÏ†êÏù¥ÎÇò ÌäπÏàò Î¨∏ÏûêÎ•º Îã®ÏàúÌûà Ï†úÏô∏ÌïòÎäî Í≤ÉÏùÄ Ïò≥ÏßÄ ÏïäÏäµÎãàÎã§. ÏΩîÌçºÏä§Ïóê ÎåÄÌïú Ï†ïÏ†ú ÏûëÏóÖÏùÑ ÏßÑÌñâÌïòÎã§Î≥¥Î©¥, Íµ¨ÎëêÏ†êÏ°∞Ï∞®ÎèÑ ÌïòÎÇòÏùò ÌÜ†ÌÅ∞ÏúºÎ°ú Î∂ÑÎ•òÌïòÍ∏∞ÎèÑ Ìï©ÎãàÎã§. Í∞ÄÏû• Í∏∞Î≥∏Ï†ÅÏù∏ ÏòàÎ•º Îì§Ïñ¥Î≥¥ÏûêÎ©¥, ÎßàÏπ®Ìëú(.)ÏôÄ Í∞ôÏùÄ Í≤ΩÏö∞Îäî Î¨∏Ïû•Ïùò Í≤ΩÍ≥ÑÎ•º Ïïå Ïàò ÏûàÎäîÎç∞ ÎèÑÏõÄÏù¥ ÎêòÎØÄÎ°ú Îã®Ïñ¥Î•º ÎΩëÏïÑÎÇº Îïå, ÎßàÏπ®Ìëú(.)Î•º Ï†úÏô∏ÌïòÏßÄ ÏïäÏùÑ Ïàò ÏûàÏäµÎãàÎã§.\n",
        "\n",
        "Îòê Îã§Î•∏ ÏòàÎ°ú Îã®Ïñ¥ ÏûêÏ≤¥Ïóê Íµ¨ÎëêÏ†êÏùÑ Í∞ñÍ≥† ÏûàÎäî Í≤ΩÏö∞ÎèÑ ÏûàÎäîÎç∞, m.p.hÎÇò Ph.DÎÇò AT&T Í∞ôÏùÄ Í≤ΩÏö∞Í∞Ä ÏûàÏäµÎãàÎã§. Îòê ÌäπÏàò Î¨∏ÏûêÏùò Îã¨Îü¨ÎÇò Ïä¨ÎûòÏãú(/)Î°ú ÏòàÎ•º Îì§Ïñ¥Î≥¥Î©¥, $45.55ÏôÄ Í∞ôÏùÄ Í∞ÄÍ≤©ÏùÑ ÏùòÎØ∏ ÌïòÍ∏∞ÎèÑ ÌïòÍ≥†, 01/02/06ÏùÄ ÎÇ†ÏßúÎ•º ÏùòÎØ∏ÌïòÍ∏∞ÎèÑ Ìï©ÎãàÎã§. Î≥¥ÌÜµ Ïù¥Îü∞ Í≤ΩÏö∞ 45.55Î•º ÌïòÎÇòÎ°ú Ï∑®Í∏âÌïòÍ≥† 45ÏôÄ 55Î°ú Îî∞Î°ú Î∂ÑÎ•òÌïòÍ≥† Ïã∂ÏßÄÎäî ÏïäÏùÑ Ïàò ÏûàÏäµÎãàÎã§.\n",
        "\n",
        "Ïà´Ïûê ÏÇ¨Ïù¥Ïóê Ïª¥Îßà(,)Í∞Ä Îì§Ïñ¥Í∞ÄÎäî Í≤ΩÏö∞ÎèÑ ÏûàÏäµÎãàÎã§. Î≥¥ÌÜµ ÏàòÏπòÎ•º ÌëúÌòÑÌï† ÎïåÎäî 123,456,789ÏôÄ Í∞ôÏù¥ ÏÑ∏ ÏûêÎ¶¨ Îã®ÏúÑÎ°ú Ïª¥ÎßàÍ∞Ä ÏûàÏäµÎãàÎã§.\n",
        "\n",
        "2) Ï§ÑÏûÑÎßêÍ≥º Îã®Ïñ¥ ÎÇ¥Ïóê ÎùÑÏñ¥Ïì∞Í∏∞Í∞Ä ÏûàÎäî Í≤ΩÏö∞.\n",
        "ÌÜ†ÌÅ∞Ìôî ÏûëÏóÖÏóêÏÑú Ï¢ÖÏ¢Ö ÏòÅÏñ¥Í∂å Ïñ∏Ïñ¥Ïùò ÏïÑÌè¨Ïä§Ìä∏Î°úÌîº(')Îäî ÏïïÏ∂ïÎêú Îã®Ïñ¥Î•º Îã§Ïãú ÌéºÏπòÎäî Ïó≠Ìï†ÏùÑ ÌïòÍ∏∞ÎèÑ Ìï©ÎãàÎã§. ÏòàÎ•º Îì§Ïñ¥ what'reÎäî what areÏùò Ï§ÑÏûÑÎßêÏù¥Î©∞, we'reÎäî we areÏùò Ï§ÑÏûÑÎßêÏûÖÎãàÎã§. ÏúÑÏùò ÏòàÏóêÏÑú reÎ•º Ï†ëÏñ¥(clitic)Ïù¥ÎùºÍ≥† Ìï©ÎãàÎã§. Ï¶â, Îã®Ïñ¥Í∞Ä Ï§ÑÏûÑÎßêÎ°ú Ïì∞Ïùº Îïå ÏÉùÍ∏∞Îäî ÌòïÌÉúÎ•º ÎßêÌï©ÎãàÎã§. Í∞ÄÎ†π I amÏùÑ Ï§ÑÏù∏ I'mÏù¥ ÏûàÏùÑ Îïå, mÏùÑ Ï†ëÏñ¥ÎùºÍ≥† Ìï©ÎãàÎã§.\n",
        "\n",
        "New YorkÏù¥ÎùºÎäî Îã®Ïñ¥ÎÇò rock 'n' rollÏù¥ÎùºÎäî Îã®Ïñ¥Î•º Î¥ÖÏãúÎã§. Ïù¥ Îã®Ïñ¥Îì§ÏùÄ ÌïòÎÇòÏùò Îã®Ïñ¥Ïù¥ÏßÄÎßå Ï§ëÍ∞ÑÏóê ÎùÑÏñ¥Ïì∞Í∏∞Í∞Ä Ï°¥Ïû¨Ìï©ÎãàÎã§. ÏÇ¨Ïö© Ïö©ÎèÑÏóê Îî∞ÎùºÏÑú, ÌïòÎÇòÏùò Îã®Ïñ¥ ÏÇ¨Ïù¥Ïóê ÎùÑÏñ¥Ïì∞Í∏∞Í∞Ä ÏûàÎäî Í≤ΩÏö∞ÏóêÎèÑ ÌïòÎÇòÏùò ÌÜ†ÌÅ∞ÏúºÎ°ú Î¥êÏïºÌïòÎäî Í≤ΩÏö∞ÎèÑ ÏûàÏùÑ Ïàò ÏûàÏúºÎØÄÎ°ú, ÌÜ†ÌÅ∞Ìôî ÏûëÏóÖÏùÄ Ï†ÄÎü¨Ìïú Îã®Ïñ¥Î•º ÌïòÎÇòÎ°ú Ïù∏ÏãùÌï† Ïàò ÏûàÎäî Îä•Î†•ÎèÑ Í∞ÄÏ†∏ÏïºÌï©ÎãàÎã§.\n",
        "\n"
      ],
      "metadata": {
        "id": "DtdT9VC6rp-d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Penn Treebank TokenizationÏùò Í∑úÏπôÏóê ÎåÄÌï¥ÏÑú ÏÜåÍ∞úÌïòÍ≥†, ÌÜ†ÌÅ∞ÌôîÏùò Í≤∞Í≥ºÎ•º ÌôïÏù∏Ìï¥Î≥¥Í≤†ÏäµÎãàÎã§.\n",
        "\n",
        "  - Í∑úÏπô 1. ÌïòÏù¥ÌëºÏúºÎ°ú Íµ¨ÏÑ±Îêú Îã®Ïñ¥Îäî ÌïòÎÇòÎ°ú Ïú†ÏßÄÌïúÎã§.\n",
        "  - Í∑úÏπô 2. doesn'tÏôÄ Í∞ôÏù¥ ÏïÑÌè¨Ïä§Ìä∏Î°úÌîºÎ°ú 'Ï†ëÏñ¥'Í∞Ä Ìï®ÍªòÌïòÎäî Îã®Ïñ¥Îäî Î∂ÑÎ¶¨Ìï¥Ï§ÄÎã§.\n",
        "\n",
        "Alert: TypeError: TreebankWordTokenizer() takes no arguments."
      ],
      "metadata": {
        "id": "x71sxg3msLG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer #WikidocsÏóêÏÑúÎäî doesn't ÏóêÏÑú Ï†ëÏñ¥ n't Î•º Îî∞Î°ú ÌÜ†ÌÅ∞Ìôî ÌïúÎã§Í≥† ÌïòÎäîÎç∞, Ïó¨Í∏∞ ÏòàÏãúÏóêÏÑúÎäî Í∑∏Î†áÏßÄ ÏïäÏùå. Ïù¥ÏÉÅÌï®...\n",
        "\n",
        "tokenizer = TreebankWordTokenizer()\n",
        "result4 = tokenizer.tokenize(obj)\n",
        "\n",
        "print('Ìä∏Î¶¨Î±ÖÌÅ¨ ÏõåÎìúÌÜ†ÌÅ¨ÎÇòÏù¥Ï†Ä : %s' %result4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4v47eMssAMO",
        "outputId": "1080915d-0277-4b6a-f649-fe7a0b7ca38e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ìä∏Î¶¨Î±ÖÌÅ¨ ÏõåÎìúÌÜ†ÌÅ¨ÎÇòÏù¥Ï†Ä : ['Here‚Äôs', 'to', 'the', 'crazy', 'ones', ',', 'the', 'misfits', ',', 'the', 'rebels', ',', 'the', 'troublemakers', ',', 'the', 'round', 'pegs', 'in', 'the', 'square', 'holes.', 'The', 'ones', 'who', 'see', 'things', 'differently', '‚Äî', 'they‚Äôre', 'not', 'fond', 'of', 'rules.', 'I', 'wanted', 'to', 'pay', 'with', 'a', 'twenty-dolloar', 'bill', ';', 'however', ',', 'but', 'she', 'couldn‚Äôt', 'get', 'cash.', 'I', 'like', 'Brown‚Äôs', 'East', 'back', 'pack', ',', 'but', 'she', 'doesn‚Äôt', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stemming"
      ],
      "metadata": {
        "id": "pXLoLgSJyTMt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lematization"
      ],
      "metadata": {
        "id": "uv4ftx76yVuB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [For Tokenization and POS in Korean, visit Wikidocs for further information](https://wikidocs.net/21698) \n",
        "* Sentence tokenizer for Korean: kss package"
      ],
      "metadata": {
        "id": "xGOApXRERwUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kss\n",
        "import kss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHP16yVbR4Z4",
        "outputId": "fd980c6a-5caa-42a8-b3e6-b4fce8ba0db9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting kss\n",
            "  Using cached kss-4.5.3.tar.gz (78 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting emoji==1.2.0 (from kss)\n",
            "  Using cached emoji-1.2.0-py3-none-any.whl (131 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from kss) (2022.10.31)\n",
            "Collecting pecab (from kss)\n",
            "  Using cached pecab-1.0.8.tar.gz (26.4 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from kss) (3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pecab->kss) (1.22.4)\n",
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from pecab->kss) (9.0.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from pecab->kss) (7.2.2)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from pytest->pecab->kss) (23.1.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->pecab->kss) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest->pecab->kss) (23.1)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->pecab->kss) (1.0.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->pecab->kss) (1.1.1)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->pecab->kss) (2.0.1)\n",
            "Building wheels for collected packages: kss, pecab\n",
            "  Building wheel for kss (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kss: filename=kss-4.5.3-py3-none-any.whl size=54258 sha256=07ac04a15bddf59d3dec45404a9d84d4124cba5b422f3945b1aaf434a9ac6e18\n",
            "  Stored in directory: /root/.cache/pip/wheels/d8/9e/a3/5b09e3f14722fa0d77f47fe840668d426760023bdd11b0fbd9\n",
            "  Building wheel for pecab (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pecab: filename=pecab-1.0.8-py3-none-any.whl size=26646666 sha256=42d490a00b3b299cfa6e398b2a3c0f1c4fcdf0c8edc88db190d4d5b49fdba482\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/6f/b4/ab61b8863d7d8b1409def8ae31adcaa089fa91b8d022ec309d\n",
            "Successfully built kss pecab\n",
            "Installing collected packages: emoji, pecab, kss\n",
            "Successfully installed emoji-1.2.0 kss-4.5.3 pecab-1.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "korfl = ('/content/sample_data/Exercise/Squall.txt', 'rt')\n",
        "korfl.read()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "RQez4XkpTjSE",
        "outputId": "b7347f0a-a227-4baa-8923-e20b989573e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-178-09b879893adf>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mkorfl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'/content/sample_data/Exercise/Squall.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mkorfl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'read'"
          ]
        }
      ]
    }
  ]
}