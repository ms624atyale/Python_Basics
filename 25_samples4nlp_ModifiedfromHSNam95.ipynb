{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Copy of nlp.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ms624atyale/Python_Basics/blob/main/25_samples4nlp_ModifiedfromHSNam95.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltUO0sYwyGfU"
      },
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "di6xZ08xsgO7"
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbHEyyNHntcZ"
      },
      "source": [
        "txt = 'Here‚Äôs to the crazy ones, the misfits, the rebels, the troublemakers, the round pegs in the square holes. \\\n",
        "The ones who see things differently ‚Äî they‚Äôre not fond of rules. \\\n",
        "You can quote them, disagree with them, glorify or vilify them, \\\n",
        "but the only thing you can‚Äôt do is ignore them because they change things. \\\n",
        "They push the human race forward, and while some may see them as the crazy ones, we see genius, \\\n",
        "because the ones who are crazy enough to think that they can change the world, are the ones who do.'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(txt)"
      ],
      "metadata": {
        "id": "2gn1acvcFo4I",
        "outputId": "fac90fbf-577d-4a90-ae1e-1b467e70d12f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here‚Äôs to the crazy ones, the misfits, the rebels, the troublemakers, the round pegs in the square holes. The ones who see things differently ‚Äî they‚Äôre not fond of rules. You can quote them, disagree with them, glorify or vilify them, but the only thing you can‚Äôt do is ignore them because they change things. They push the human race forward, and while some may see them as the crazy ones, we see genius, because the ones who are crazy enough to think that they can change the world, are the ones who do.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = open('/content/sample_data/exercise/crime_punishment_sample.txt', 'rt') #Don't forget to load your txt file!\n",
        "text = file.read().replace(\"\\n\", \" \")\n",
        "file.close()"
      ],
      "metadata": {
        "id": "btgs9Nt-2Yj-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45jV2UYs1GEC",
        "outputId": "474e02a0-8aee-44d9-bdc7-a6af31942ab9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "txt.split()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Here‚Äôs',\n",
              " 'to',\n",
              " 'the',\n",
              " 'crazy',\n",
              " 'ones,',\n",
              " 'the',\n",
              " 'misfits,',\n",
              " 'the',\n",
              " 'rebels,',\n",
              " 'the',\n",
              " 'troublemakers,',\n",
              " 'the',\n",
              " 'round',\n",
              " 'pegs',\n",
              " 'in',\n",
              " 'the',\n",
              " 'square',\n",
              " 'holes.',\n",
              " 'The',\n",
              " 'ones',\n",
              " 'who',\n",
              " 'see',\n",
              " 'things',\n",
              " 'differently',\n",
              " '‚Äî',\n",
              " 'they‚Äôre',\n",
              " 'not',\n",
              " 'fond',\n",
              " 'of',\n",
              " 'rules.',\n",
              " 'You',\n",
              " 'can',\n",
              " 'quote',\n",
              " 'them,',\n",
              " 'disagree',\n",
              " 'with',\n",
              " 'them,',\n",
              " 'glorify',\n",
              " 'or',\n",
              " 'vilify',\n",
              " 'them,',\n",
              " 'but',\n",
              " 'the',\n",
              " 'only',\n",
              " 'thing',\n",
              " 'you',\n",
              " 'can‚Äôt',\n",
              " 'do',\n",
              " 'is',\n",
              " 'ignore',\n",
              " 'them',\n",
              " 'because',\n",
              " 'they',\n",
              " 'change',\n",
              " 'things.',\n",
              " 'They',\n",
              " 'push',\n",
              " 'the',\n",
              " 'human',\n",
              " 'race',\n",
              " 'forward,',\n",
              " 'and',\n",
              " 'while',\n",
              " 'some',\n",
              " 'may',\n",
              " 'see',\n",
              " 'them',\n",
              " 'as',\n",
              " 'the',\n",
              " 'crazy',\n",
              " 'ones,',\n",
              " 'we',\n",
              " 'see',\n",
              " 'genius,',\n",
              " 'because',\n",
              " 'the',\n",
              " 'ones',\n",
              " 'who',\n",
              " 'are',\n",
              " 'crazy',\n",
              " 'enough',\n",
              " 'to',\n",
              " 'think',\n",
              " 'that',\n",
              " 'they',\n",
              " 'can',\n",
              " 'change',\n",
              " 'the',\n",
              " 'world,',\n",
              " 'are',\n",
              " 'the',\n",
              " 'ones',\n",
              " 'who',\n",
              " 'do.']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFR-cRaahTPy",
        "outputId": "23878c2e-3f81-44b7-e1fa-c271dc6549d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "' '.join(txt.split())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Here‚Äôs to the crazy ones, the misfits, the rebels, the troublemakers, the round pegs in the square holes. The ones who see things differently ‚Äî they‚Äôre not fond of rules. You can quote them, disagree with them, glorify or vilify them, but the only thing you can‚Äôt do is ignore them because they change things. They push the human race forward, and while some may see them as the crazy ones, we see genius, because the ones who are crazy enough to think that they can change the world, are the ones who do.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "lGpNCLnQHGvl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üÜò What is PunktSentenceTokenizer? \n",
        "* [For more information read the original article](https://www.askpython.com/python-modules/nltk-punkt)\n",
        "\n",
        "In NLTK, PUNKT is an <font color = 'brown'> **unsupervised trainable model**</font>, which means it can be **trained on unlabeled data** (Data that has not been tagged with information identifying its characteristics, properties, or categories is referred to as unlabeled data.)\n",
        "\n",
        "It generates a list of sentences from a text by developing a model for **words that start sentences, prepositional phrases, and abbreviations** using an unsupervised technique. Without first being put to use, it has to be trained on a sizable amount of plaintext in the intended language."
      ],
      "metadata": {
        "id": "PaMm4fnFe67P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#‚õî <font color = 'red'> Q: module Îî∞Î°ú Î∂àÎü¨Îì§Ïó¨Ïïº ÌïòÏßÄ ÏïäÎÇò? Delete later. "
      ],
      "metadata": {
        "id": "_v9SOJjRghF-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gq_lPZMHntcb",
        "outputId": "89567312-b687-439f-d0dc-edc45c85b90e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "words = word_tokenize(txt)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#‚õî <font color = 'red'> Q:RE \"[\\w]+\"?Î•º Ï†ÅÏö©Ìï¥ÏÑú Ïñ¥Îñ§ Í≤∞Í≥ºÍ∞Ä ÎÇòÏò§ÎäîÏßÄ Ïù¥Ìï¥X. Delete later. "
      ],
      "metadata": {
        "id": "piEwdVuig_U_"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RC1fe7nWF6wN",
        "outputId": "f013a16c-7164-4ee3-e6c6-e1abe6940fa0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.tokenize import RegexpTokenizer\n",
        "retokenize = RegexpTokenizer(\"[\\w]+\")\n",
        "words = retokenize.tokenize(txt)\n",
        "words"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Here',\n",
              " 's',\n",
              " 'to',\n",
              " 'the',\n",
              " 'crazy',\n",
              " 'ones',\n",
              " 'the',\n",
              " 'misfits',\n",
              " 'the',\n",
              " 'rebels',\n",
              " 'the',\n",
              " 'troublemakers',\n",
              " 'the',\n",
              " 'round',\n",
              " 'pegs',\n",
              " 'in',\n",
              " 'the',\n",
              " 'square',\n",
              " 'holes',\n",
              " 'The',\n",
              " 'ones',\n",
              " 'who',\n",
              " 'see',\n",
              " 'things',\n",
              " 'differently',\n",
              " 'they',\n",
              " 're',\n",
              " 'not',\n",
              " 'fond',\n",
              " 'of',\n",
              " 'rules',\n",
              " 'You',\n",
              " 'can',\n",
              " 'quote',\n",
              " 'them',\n",
              " 'disagree',\n",
              " 'with',\n",
              " 'them',\n",
              " 'glorify',\n",
              " 'or',\n",
              " 'vilify',\n",
              " 'them',\n",
              " 'but',\n",
              " 'the',\n",
              " 'only',\n",
              " 'thing',\n",
              " 'you',\n",
              " 'can',\n",
              " 't',\n",
              " 'do',\n",
              " 'is',\n",
              " 'ignore',\n",
              " 'them',\n",
              " 'because',\n",
              " 'they',\n",
              " 'change',\n",
              " 'things',\n",
              " 'They',\n",
              " 'push',\n",
              " 'the',\n",
              " 'human',\n",
              " 'race',\n",
              " 'forward',\n",
              " 'and',\n",
              " 'while',\n",
              " 'some',\n",
              " 'may',\n",
              " 'see',\n",
              " 'them',\n",
              " 'as',\n",
              " 'the',\n",
              " 'crazy',\n",
              " 'ones',\n",
              " 'we',\n",
              " 'see',\n",
              " 'genius',\n",
              " 'because',\n",
              " 'the',\n",
              " 'ones',\n",
              " 'who',\n",
              " 'are',\n",
              " 'crazy',\n",
              " 'enough',\n",
              " 'to',\n",
              " 'think',\n",
              " 'that',\n",
              " 'they',\n",
              " 'can',\n",
              " 'change',\n",
              " 'the',\n",
              " 'world',\n",
              " 'are',\n",
              " 'the',\n",
              " 'ones',\n",
              " 'who',\n",
              " 'do']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(words)"
      ],
      "metadata": {
        "id": "wxVkzTpOHO29",
        "outputId": "9fb1f853-b150-4f84-8929-a02dad599acc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Here', 's', 'to', 'the', 'crazy', 'ones', 'the', 'misfits', 'the', 'rebels', 'the', 'troublemakers', 'the', 'round', 'pegs', 'in', 'the', 'square', 'holes', 'The', 'ones', 'who', 'see', 'things', 'differently', 'they', 're', 'not', 'fond', 'of', 'rules', 'You', 'can', 'quote', 'them', 'disagree', 'with', 'them', 'glorify', 'or', 'vilify', 'them', 'but', 'the', 'only', 'thing', 'you', 'can', 't', 'do', 'is', 'ignore', 'them', 'because', 'they', 'change', 'things', 'They', 'push', 'the', 'human', 'race', 'forward', 'and', 'while', 'some', 'may', 'see', 'them', 'as', 'the', 'crazy', 'ones', 'we', 'see', 'genius', 'because', 'the', 'ones', 'who', 'are', 'crazy', 'enough', 'to', 'think', 'that', 'they', 'can', 'change', 'the', 'world', 'are', 'the', 'ones', 'who', 'do']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pc42Plwx56YS"
      },
      "source": [
        "### Normalization  \n",
        "Stemming: am ‚Üí am, the going ‚Üí the go, having ‚Üí hav  \n",
        "Lemmatization: am ‚Üí be, the going ‚Üí the going, having ‚Üí have"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#‚õî <font color = 'red'> Q:RE stem ÏùÄ 1Ï§ÑÏóêÏÑú Î™®Îìà Í∞ôÏùÄÎç∞, 3Ï§ÑÏóêÏÑú stem(w)ÎùºÍ≥† ÏÇ¨Ïö©Îêú Í≤É Î≥¥Î©¥ Ìï®Ïàò Í∞ôÏùÄÎç∞... Ïù¥Îü∞ Í≤ÉÎì§ÏùÄ ÌïôÏÉùÎì§ÏóêÍ≤å Ïñ¥ÎñªÍ≤å ÏÑ§Î™ÖÌï¥Ïïº ÌïòÎÇò?  Delete later."
      ],
      "metadata": {
        "id": "TOlfnt7hhj_1"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsFfoAr259Fs"
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "[stemmer.stem(w) for w in words] # words Î°ú list comprehension. Ïù¥ ÏõåÏ¶àÏóêÏÑú ÌïòÎÇòÌïòÎÇòÏî© Î£®ÌîÑÎ•º ÎèÑÎäîÎç∞, Îã®Ïñ¥Î•º w Ïóê Îã¥ÏïÑÏÑú, ÏïûÏóê stemmer.stem () Ìï®ÏàòÍ∞Ä Ïã§ÌñâÎêúÎã§. Ïñ¥Îñ§ Ìï®ÏàòÎäî Ïñ¥Îñ§ Ïû•/Îã®Ï†êÏù¥ ÏûàÍµ¨ÎÇò.  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkbgNiPd8BdL"
      },
      "source": [
        "from nltk.stem import LancasterStemmer\n",
        "stemmer = LancasterStemmer()\n",
        "[stemmer.stem(w) for w in words]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üëÄ **WordNet** is just another NLTK corpus reader, and can be imported like this:\n",
        "\n",
        "[For more information, you can read the original article](https://www.nltk.org/howto/wordnet.html)\n",
        ">> from nltk.corpus import wordnet as wn\n",
        "\n",
        "Look up a word using synsets(); this function has an optional pos argument which lets you constrain the part of speech of the word:\n",
        "\n",
        ">> wn.synsets('dog', pos=wn.VERB)\n",
        "\n",
        ">> [Synset('chase.v.01')]\n"
      ],
      "metadata": {
        "id": "7ZGPXKWHjfvz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#‚õî <font color = 'red'> Q: WordNetLemmatizerÏôÄÎäî Îã§Î•¥Í≤å download Ìï®ÏàòÎäî Í∏∞Î≥∏Ìï®ÏàòÎùºÏÑú Î∞îÎ°ú ÏÇ¨Ïö© Í∞ÄÎä•. ÏòàÏãú: print().\n",
        "\n",
        "#‚õî <font color = 'red'> Q: Ï∞æÎã§Í∞Ä Î¥§ÎäîÎç∞, function1.function2() Ïù¥Î†áÍ≤å ÏÇ¨Ïö©ÌïòÎäî Í≤ΩÏö∞ÎèÑ ÌùîÌïúÏßÄ? Ïù¥Í≤ÉÍ≥º function1(function2()) ÏôÄÎäî Ïñ¥ÎñªÍ≤å Îã§Î•∏ÏßÄ... ÏïÑÎûò lemmatizer.lemmatize(w) Delete later"
      ],
      "metadata": {
        "id": "nNlyHyuSiTkB"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIIh5pYd8f74"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer # ÌôúÏö©ÏùÑ Î≥µÏõêÌïòÏó¨ Îã®Ïñ¥Î•º Ï∂îÏ∂úÌï¥Ï§å. \n",
        "nltk.download('wordnet')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "[lemmatizer.lemmatize(w) for w in words]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Stopwords** Î∂àÏö©Ïñ¥\n",
        "\n",
        "[For more information, read the original article](https://pythonspot.com/nltk-stop-words/)\n",
        "\n",
        "* Stopwords are the English words which does not add much meaning to a sentence. They can safely be ignored without sacrificing the meaning of the sentence. For example, the words like the, he, have etc. Such words are already captured this in corpus named corpus. We first download it to our python environment.\n",
        "\n",
        "* Stop words are common words like ‚Äòthe‚Äô, ‚Äòand‚Äô, ‚ÄòI‚Äô, etc. that are very frequent in text, and so don‚Äôt convey insights into the specific topic of a document. We can remove these stop words from the text in a given corpus to clean up the data, and identify words that are more rare and potentially more relevant to what we‚Äôre interested in.\n",
        "\n",
        "* Text may contain stop words like ‚Äòthe‚Äô, ‚Äòis‚Äô, ‚Äòare‚Äô. Stop words can be filtered from the text to be processed. There is no universal list of stop words in nlp research, however the nltk module contains a list of stop words."
      ],
      "metadata": {
        "id": "Y49DTFpdmehh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPgIzrjm8_1N"
      },
      "source": [
        "### Stopword"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk #üçÑ package or module? "
      ],
      "metadata": {
        "id": "zOljqQEKIqXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚õî Q: Ìï®Ïàò Ïó∞ÏÜç ÏÇ¨Ïö©Ïóê Í∑úÏπôÏùÄ Î≠îÍ∞Ä? function1(function(2)); function1.function2()"
      ],
      "metadata": {
        "id": "Nw9Z2rE4q3bv"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdM2FaN8ntcc",
        "outputId": "5a031bb0-ad02-46b3-cca9-8524ba239264",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.corpus import stopwords  \n",
        "nltk.download('stopwords') #ÌïÑÏöîÌïú Î™®Îìà??ÎùºÏÑú Îî∞Î°ú Îã§Ïö¥Î°úÎìú Ìï®.\n",
        "words = [w for w in words if not w in stopwords.words('english')] #üçÑ codeline Ìï¥ÏÑù Î™ªÌï®X. words Îäî Î≥ÄÏàòÏù∏Îç∞, Ïôú Ìï®Ïàò()Ï≤òÎüº Ïì∞Ïù¥ÏßÄ? \n",
        "print(words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Here', 'crazy', 'ones', 'misfits', 'rebels', 'troublemakers', 'round', 'pegs', 'square', 'holes', 'The', 'ones', 'see', 'things', 'differently', 'fond', 'rules', 'You', 'quote', 'disagree', 'glorify', 'vilify', 'thing', 'ignore', 'change', 'things', 'They', 'push', 'human', 'race', 'forward', 'may', 'see', 'crazy', 'ones', 'see', 'genius', 'ones', 'crazy', 'enough', 'think', 'change', 'world', 'ones']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmwXTL0UA5aw"
      },
      "source": [
        "### Collocation, Concordance (To do list as of May 18, 2023)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fll4ygxNA3OJ"
      },
      "source": [
        "nltk.download('gutenberg')\n",
        "text = nltk.corpus.gutenberg.raw('austen-emma.txt') #Package.Module.gutenbergÏûêÎ£å.raw()Ìï®Ïàò\n",
        "words = retokenize.tokenize(text)#?? [\\w]+ REÏùÑ Ï†ÅÏö©Ìïú Í≤∞Í≥ºÎ•º Ìï†ÎãπÌïú retokenize Î≥ÄÏàòÏóê ÏúÑÏùò textÎ≥ÄÏàòÎ•º ÌÜ†ÌÅ∞ÌôîÌïòÎäî Ìï®Ïàò ÏÇ¨Ïö© "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TuKfbhCX0-1m"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqVXlhIrAtmf"
      },
      "source": [
        "nltk.Text(words).collocations()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aq0wiutwA_au"
      },
      "source": [
        "nltk.Text(words).concordance('Emma', 79, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hIAIhXvP_BjU"
      },
      "source": [
        "nltk.Text(words).dispersion_plot([\"Emma\", \"Knightley\", \"Frank\", \"Jane\", \"Harriet\", \"Robert\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWYZOFxq_ex2"
      },
      "source": [
        "nltk.Text(words).similar(\"Emma\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZihiVSBK_vy7"
      },
      "source": [
        "nltk.Text(words).common_contexts([\"Emma\", \"she\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8TrCE14vGcT"
      },
      "source": [
        "### Frequency distribution, Frequency plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdY3m6zSBHic"
      },
      "source": [
        "fd = nltk.FreqDist(words).most_common(20)\n",
        "fd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tpZThNV-ftv"
      },
      "source": [
        "nltk.Text(words).plot(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSOSzIovvKvE"
      },
      "source": [
        "### Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIcAOAvqntce"
      },
      "source": [
        "nltk.download('words')\n",
        "nltk.corpus.words.words('en')[-20:-1]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GjAy_Ju7ntce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30d2cf84-b481-4e7b-82fa-81bcf0ca4555"
      },
      "source": [
        "len(nltk.corpus.words.words('en'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "235886"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrVGVc0X9j7r"
      },
      "source": [
        "### Regular expression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQKgoQFI_cG-"
      },
      "source": [
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7U2pS-NL9p38"
      },
      "source": [
        "'''       Basic Regular Expression Meta-Characters, Including Wildcards, Ranges and Closures\n",
        "\n",
        ".\t        Wildcard, matches any character\n",
        "^abc\t    Matches some pattern abc at the start of a string\n",
        "abc$\t    Matches some pattern abc at the end of a string\n",
        "[abc]\t    Matches one of a set of characters\n",
        "[^abc]    Matches anything but a set of characters\n",
        "[A-Z0-9]\tMatches one of a range of characters\n",
        "ed|ing|s\tMatches one of the specified strings (disjunction)\n",
        "*\t        Zero or more of previous item, e.g. a*, [a-z]* (also known as Kleene Closure)\n",
        "+\t        One or more of previous item, e.g. a+, [a-z]+\n",
        "?\t        Zero or one of the previous item (i.e. optional), e.g. a?, [a-z]?\n",
        "{n}\t      Exactly n repeats where n is a non-negative integer\n",
        "{n,}\t    At least n repeats\n",
        "{,n}\t    No more than n repeats\n",
        "{m,n}\t    At least m and no more than n repeats\n",
        "a(b|c)+\t  Parentheses that indicate the scope of the operators\n",
        "(...)     Matches whatever regular expression is inside the parentheses\n",
        "\\d\n",
        "Matches any decimal digit; this is equivalent to the class [0-9].\n",
        "\\D\n",
        "Matches any non-digit character; this is equivalent to the class [^0-9].\n",
        "\\s\n",
        "Matches any whitespace character; this is equivalent to the class [ \\t\\n\\r\\f\\v].\n",
        "\\S\n",
        "Matches any non-whitespace character; this is equivalent to the class [^ \\t\\n\\r\\f\\v].\n",
        "\\w\n",
        "Matches any alphanumeric character; this is equivalent to the class [a-zA-Z0-9_].\n",
        "\\W\n",
        "Matches any non-alphanumeric character; this is equivalent to the class [^a-zA-Z0-9_].\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sp3_Dm9Q_tNQ"
      },
      "source": [
        "engdict = nltk.corpus.words.words('en')\n",
        "\n",
        "result = [w for w in engdict if re.search('ed$', w)]\n",
        "# result = [w for w in engdict if re.search('^..j..t..$', w)]\n",
        "# result = [w for w in engdict if re.search('^[ghi][mno][jlk][def]$', w)]\n",
        "# result = [w for w in engdict if re.search('^[ah]+$', w)][:10]\n",
        "print(result[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1a5mQYj4hwn"
      },
      "source": [
        "nltk.download('treebank')\n",
        "wsj = nltk.corpus.treebank.words()\n",
        "\n",
        "result = [w for w in wsj if re.search('(ed|ing)$', w)]\n",
        "# result = [w for w in wsj if re.search('^[0-9]+\\.[0-9]+$', w)]\n",
        "# result = [w for w in wsj if re.search('^[A-Z]+\\$$', w)]\n",
        "# result = [w for w in wsj if re.search('^[0-9]{4}$', w)]\n",
        "# result = [w for w in wsj if re.search('^[0-9]+-[a-z]{3,5}$', w)]\n",
        "# result = [w for w in wsj if re.search('^[a-z]{5,}-[a-z]{2,3}-[a-z]{,6}$', w)]\n",
        "\n",
        "result = sorted(set(result))\n",
        "print(result[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyIIqwosCRZa"
      },
      "source": [
        "### Extract information (pos tag, named entity)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VBiObftCVwH"
      },
      "source": [
        "sent = \"I am Jhon from America and would like to go to Starbuck\"\n",
        "words = nltk.word_tokenize(sent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2HuyzFWCe3U"
      },
      "source": [
        "'''\n",
        "POS tag list:\n",
        "\n",
        "CC\tcoordinating conjunction\n",
        "CD\tcardinal digit\n",
        "DT\tdeterminer\n",
        "EX\texistential there (like: \"there is\" ... think of it like \"there exists\")\n",
        "FW\tforeign word\n",
        "IN\tpreposition/subordinating conjunction\n",
        "JJ\tadjective\t'big'\n",
        "JJR\tadjective, comparative\t'bigger'\n",
        "JJS\tadjective, superlative\t'biggest'\n",
        "LS\tlist marker\t1)\n",
        "MD\tmodal\tcould, will\n",
        "NN\tnoun, singular 'desk'\n",
        "NNS\tnoun plural\t'desks'\n",
        "NNP\tproper noun, singular\t'Harrison'\n",
        "NNPS\tproper noun, plural\t'Americans'\n",
        "PDT\tpredeterminer\t'all the kids'\n",
        "POS\tpossessive ending\tparent's\n",
        "PRP\tpersonal pronoun\tI, he, she\n",
        "PRP$\tpossessive pronoun\tmy, his, hers\n",
        "RB\tadverb\tvery, silently,\n",
        "RBR\tadverb, comparative\tbetter\n",
        "RBS\tadverb, superlative\tbest\n",
        "RP\tparticle\tgive up\n",
        "TO\tto\tgo 'to' the store.\n",
        "UH\tinterjection\terrrrrrrrm\n",
        "VB\tverb, base form\ttake\n",
        "VBD\tverb, past tense\ttook\n",
        "VBG\tverb, gerund/present participle\ttaking\n",
        "VBN\tverb, past participle\ttaken\n",
        "VBP\tverb, sing. present, non-3d\ttake\n",
        "VBZ\tverb, 3rd person sing. present\ttakes\n",
        "WDT\twh-determiner\twhich\n",
        "WP\twh-pronoun\twho, what\n",
        "WP$\tpossessive wh-pronoun\twhose\n",
        "WRB\twh-abverb\twhere, when\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwKdu36WCewv"
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "pos = nltk.pos_tag(words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnjGT1HpClE0"
      },
      "source": [
        "nltk.download('maxent_ne_chunker')\n",
        "NE = nltk.ne_chunk(pos)\n",
        "# common Entity types: ORGANIZATION, PERSON, LOCATION, DATE, TIME, MONEY, and GPE (geo-political entity)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jt9DEIZ4lXQF"
      },
      "source": [
        "### Wordcloud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jypxOnw9hoyZ"
      },
      "source": [
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "text = nltk.corpus.gutenberg.raw('bible-kjv.txt')\n",
        "\n",
        "wc = WordCloud().generate(text) \n",
        "plt.imshow(wc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6xv5ClAl5xk"
      },
      "source": [
        "stopwords = set(STOPWORDS) \n",
        "stopwords.add('unto')\n",
        "wc = WordCloud(stopwords = stopwords).generate(text) \n",
        "plt.imshow(wc)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}